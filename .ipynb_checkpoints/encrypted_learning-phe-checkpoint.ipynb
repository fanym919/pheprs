{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0092a796",
   "metadata": {},
   "source": [
    "# Homomorphic Encryption and Federated Learning based Privacy-Preserving: Breast cancer detection Use-Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ed5aad",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "Medical data is often highly sensitive in terms of data privacy and security concerns. Federated learning, one type of machine learning techniques, has been started to use for the improvement of the privacy and security of medical data. In the federated learning, the training data is distributed across multiple machines, and the\n",
    "learning process is performed in a collaborative manner. There are several privacy attacks on machine learning (ML) models to get the sensitive information by attackers. Therefore, the ML model itself should be protected from the adversarial attack, especially for applications using medical data. One of the solutions for this problem is homomorphic encryption-based model protection from the adversary collaborator. This project proposes a privacy-preserving federated learning algorithm for medical data using homomorphic encryption. The proposed algorithm uses a secure multi-party computation protocol to protect the machine learning model from the adversaries. In this study, the proposed algorithm using a real-world medical dataset is evaluated in terms of the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c7f12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2024-10-17T21:58:37.248815-04:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.12\n",
      "IPython version      : 8.28.0\n",
      "\n",
      "Compiler    : GCC 11.4.0\n",
      "OS          : Linux\n",
      "Release     : 6.8.0-40-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 12\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5590bb95",
   "metadata": {},
   "source": [
    "Before step into federated learning, lets talk about Logistic Regression - a local training method we use in our federated learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132c4ab1",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2be267bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  fractal_dimension_worst  radius_mean  texture_mean  \\\n",
       "0    842302                  0.11890        17.99         10.38   \n",
       "1    842517                  0.08902        20.57         17.77   \n",
       "2  84300903                  0.08758        19.69         21.25   \n",
       "3  84348301                  0.17300        11.42         20.38   \n",
       "4  84358402                  0.07678        20.29         14.34   \n",
       "\n",
       "   perimeter_mean  area_mean  smoothness_mean  compactness_mean  \\\n",
       "0          122.80     1001.0          0.11840           0.27760   \n",
       "1          132.90     1326.0          0.08474           0.07864   \n",
       "2          130.00     1203.0          0.10960           0.15990   \n",
       "3           77.58      386.1          0.14250           0.28390   \n",
       "4          135.10     1297.0          0.10030           0.13280   \n",
       "\n",
       "   concavity_mean  concave points_mean  ...  radius_worst  texture_worst  \\\n",
       "0          0.3001              0.14710  ...         25.38          17.33   \n",
       "1          0.0869              0.07017  ...         24.99          23.41   \n",
       "2          0.1974              0.12790  ...         23.57          25.53   \n",
       "3          0.2414              0.10520  ...         14.91          26.50   \n",
       "4          0.1980              0.10430  ...         22.54          16.67   \n",
       "\n",
       "   perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0           184.60      2019.0            0.1622             0.6656   \n",
       "1           158.80      1956.0            0.1238             0.1866   \n",
       "2           152.50      1709.0            0.1444             0.4245   \n",
       "3            98.87       567.7            0.2098             0.8663   \n",
       "4           152.20      1575.0            0.1374             0.2050   \n",
       "\n",
       "   concavity_worst  concave points_worst  symmetry_worst  diagnosis  \n",
       "0           0.7119                0.2654          0.4601          M  \n",
       "1           0.2416                0.1860          0.2750          M  \n",
       "2           0.4504                0.2430          0.3613          M  \n",
       "3           0.6869                0.2575          0.6638          M  \n",
       "4           0.4000                0.1625          0.2364          M  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# we use another datasets to demo our Logistic Regression\n",
    "df = pd.read_csv(\"data/breast-cancer.csv\")\n",
    "\n",
    "# define function to swap columns\n",
    "def swap_columns(df, col1, col2):\n",
    "    col_list = list(df.columns)\n",
    "    x, y = col_list.index(col1), col_list.index(col2)\n",
    "    col_list[y], col_list[x] = col_list[x], col_list[y]\n",
    "    df = df[col_list]\n",
    "    return df\n",
    "\n",
    "# swap \"diagnosis\" and \"fractal_dimension_worst\" columns\n",
    "df = swap_columns(df, 'diagnosis', 'fractal_dimension_worst')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db30fcc",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17a0ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7366ae",
   "metadata": {},
   "source": [
    "Replace \"M\" with 1 and \"B\" with 0 at \"diagnosis\" column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9548210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace \"M\" with 1 and \"B\" with 0\n",
    "df[\"diagnosis\"] = (df[\"diagnosis\"] == \"M\").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8836ba",
   "metadata": {},
   "source": [
    "We define some functions in order to randomly split this dataset to:\n",
    "- Training dataset (80%)\n",
    "- Testing dataset  (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "188c50f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset(name, data):\n",
    "    print('Dataset {}. Shape: {}'.format(name, data.shape))\n",
    "    print(data[:5])\n",
    "    \n",
    "def scale_dataset(df, overSample=False):\n",
    "    # split to fetures and diagnostic result\n",
    "    X = df[df.columns[:-1]].values\n",
    "    Y = df[df.columns[-1]].values\n",
    "    \n",
    "    # standardize the input features \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # balance the class distribution\n",
    "    if overSample:\n",
    "        ros = RandomOverSampler()\n",
    "        X, Y = ros.fit_resample(X, Y)\n",
    "\n",
    "    data = np.hstack((X, np.reshape(Y, (-1, 1))))\n",
    "    \n",
    "    # convert to tensor context\n",
    "    X_train_tensor = Variable(torch.tensor(X, dtype = torch.float32))\n",
    "    Y_train_tensor = Variable(torch.tensor(Y, dtype = torch.float32))\n",
    "    data_tensor    = Variable(torch.tensor(data, dtype = torch.float32))\n",
    "    \n",
    "    return data_tensor, X_train_tensor, Y_train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "429b827c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fanyo/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2353,  0.4794, -0.5685,  ..., -0.5120,  0.8944,  0.0000],\n",
       "        [-0.1631,  0.7001, -0.1503,  ..., -0.1522,  0.7649,  0.0000],\n",
       "        [-0.2354,  0.5417,  0.0659,  ...,  0.6291, -0.2917,  1.0000],\n",
       "        ...,\n",
       "        [ 0.5044,  4.9582, -0.7876,  ...,  2.1734,  5.8994,  1.0000],\n",
       "        [-0.2355, -0.4242,  1.5993,  ...,  1.8875, -0.2127,  1.0000],\n",
       "        [-0.2355, -0.4737,  1.9834,  ...,  1.3080, -0.1275,  1.0000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataframe to train and test df\n",
    "df_train, df_test = np.split(df.sample(frac=1), [int(0.8 * len(df))])\n",
    "\n",
    "# scaling and convert to tensor context\n",
    "train, X_train, Y_train = scale_dataset(df_train, True)\n",
    "test , X_test , Y_test  = scale_dataset(df_test , False)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514f8b55",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9ddc6",
   "metadata": {},
   "source": [
    "We define our machine learning model, which is a logistic regression model. Why? Because this medical dataset is linearly separable, which simplifies things a lot.\n",
    "\n",
    "We can create the logistic regression model with the following code (we will using [pyTorch](https://en.wikipedia.org/wiki/PyTorch) in our project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a32c86c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "669c0951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        # init super class of LogisticRegression\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        \n",
    "        # create \"linear neural network\"\n",
    "        input_dim  = num_features\n",
    "        output_dim = 1\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "        # initialize Weights and Bias\n",
    "        self.linear.weight.detach().zero_()\n",
    "        self.linear.bias.detach().zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c7eb24",
   "metadata": {},
   "source": [
    "In our “forward” pass of the PyTorch neural network (really just a perceptron), Logistic regression can also be visualized as a network of features feeding into a single logistic function, the visual representation and corresponding equations are shown below:\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='images/logistic_model_overview.png'>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d690b8d",
   "metadata": {},
   "source": [
    "### Sigmoid function\n",
    "\n",
    "The sigmoid function is extremely useful for two main reasons:\n",
    "\n",
    "* It transforms our linear regression output to a probability from 0 to 1. We can then take any probability greater than 0.5 as being 1 and below as being 0.\n",
    "\n",
    "* Unlike a stepwise function (which would transform the data into the binary case as well), the sigmoid is differentiable, which is necessary for optimizing the parameters using gradient descent (we will show later).\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='images/sigmoid.png'>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51f8f15",
   "metadata": {},
   "source": [
    "### Training process\n",
    "\n",
    "Firstly, we should assign some hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ec346ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 31 # numbers of features \n",
    "epochs = 10000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78085473",
   "metadata": {},
   "source": [
    "Parameter Definitions:\n",
    "\n",
    "* **Epoch**: Indicates the number of passes through the entire training dataset the network has completed.\n",
    "* **learning_rate**: A tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1e760bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def decide(y):\n",
    "    return 1. if y >= 0.5 else 0.\n",
    "\n",
    "decide_vectorized = np.vectorize(decide)\n",
    "to_percent = lambda x: '{:.2f}%'.format(x)\n",
    "\n",
    "def compute_accuracy(model, input, output):\n",
    "    prediction = model(input).data.numpy()[:, 0]\n",
    "    n_samples = prediction.shape[0] + 0.\n",
    "    prediction = decide_vectorized(prediction)\n",
    "    equal = prediction == output.data.numpy()\n",
    "    return 100. * equal.sum() / n_samples\n",
    "\n",
    "def Training(X_train, Y_train, X_test, Y_test, debug=True):\n",
    "    model = LogisticRegression(input_dim)\n",
    "    n_samples, _ = X_train.shape\n",
    "    \n",
    "    # record losses and accuracies during training\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    # define criterion function and set up optimizer\n",
    "    criterion = torch.nn.BCELoss(reduction='mean')\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "    \n",
    "    # main process\n",
    "    for epoch in tqdm(range(epochs)):  \n",
    "        optimizer.zero_grad()\n",
    "        #### Compute outputs ####\n",
    "        prediction = model(X_train)\n",
    "        \n",
    "        #### Compute gradients ####\n",
    "        loss = criterion(prediction.squeeze(), Y_train)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        #### Update weights #### \n",
    "        optimizer.step()\n",
    "            \n",
    "        #### Logging ####\n",
    "        if debug and (epoch + 1)%50 == 0:\n",
    "            # compute accuracy and loss\n",
    "            train_acc = compute_accuracy(model, X_train, Y_train)\n",
    "            train_loss = loss.item()\n",
    "            losses.append(train_loss)\n",
    "            accuracies.append(train_acc)\n",
    "            \n",
    "            print('[LOG] Epoch: %05d' % (epoch + 1), end=\"\")\n",
    "            print('    | Train ACC: %s' % to_percent(train_acc), end=\"\")\n",
    "            print('    | Loss: %.3f' % train_loss)\n",
    "\n",
    "    recorded = [accuracies, losses]\n",
    "    return model, recorded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e289c595",
   "metadata": {},
   "source": [
    "In this above code, we introduce two important functions: the Loss Function and the Optimizer\n",
    "\n",
    "**Binary Cross Entropy Loss Function**\n",
    "\n",
    "```python\n",
    "criterion = torch.nn.BCELoss(reduction='mean')\n",
    "```\n",
    "<p align='center'>\n",
    "    <img src='images/loss_function.png'>\n",
    "</p>\n",
    "\n",
    "* $m$: Number of training examples\n",
    "* $y$: The true $y$ value\n",
    "* $\\hat{y}$: Predicted $y$ value\n",
    "\n",
    "**Stochastic Gradient Descent Optimizer**\n",
    "\n",
    "```python\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "```\n",
    "\n",
    "We update the parameters to minimize the loss function with the following equations:\n",
    "\n",
    "* Update model **Weights**:\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='images/update_w.webp'>\n",
    "</p>\n",
    "\n",
    "* Update model **Bias**:\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='images/update_b.webp'>\n",
    "</p>\n",
    "\n",
    "where $\\alpha$ is the **learning_rate**\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='images/gradient_descent.png' title='Gradient Descent'>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7197c",
   "metadata": {},
   "source": [
    "Demo our training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31ad3d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708c1cc1a165449e8b3f4c6a8b431a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Epoch: 00050    | Train ACC: 94.19%    | Loss: 0.319\n",
      "[LOG] Epoch: 00100    | Train ACC: 94.54%    | Loss: 0.244\n",
      "[LOG] Epoch: 00150    | Train ACC: 94.72%    | Loss: 0.208\n",
      "[LOG] Epoch: 00200    | Train ACC: 95.77%    | Loss: 0.186\n",
      "[LOG] Epoch: 00250    | Train ACC: 96.30%    | Loss: 0.171\n",
      "[LOG] Epoch: 00300    | Train ACC: 96.83%    | Loss: 0.159\n",
      "[LOG] Epoch: 00350    | Train ACC: 97.54%    | Loss: 0.150\n",
      "[LOG] Epoch: 00400    | Train ACC: 97.54%    | Loss: 0.143\n",
      "[LOG] Epoch: 00450    | Train ACC: 97.54%    | Loss: 0.137\n",
      "[LOG] Epoch: 00500    | Train ACC: 97.54%    | Loss: 0.132\n",
      "[LOG] Epoch: 00550    | Train ACC: 97.54%    | Loss: 0.128\n",
      "[LOG] Epoch: 00600    | Train ACC: 97.89%    | Loss: 0.124\n",
      "[LOG] Epoch: 00650    | Train ACC: 97.89%    | Loss: 0.120\n",
      "[LOG] Epoch: 00700    | Train ACC: 97.89%    | Loss: 0.117\n",
      "[LOG] Epoch: 00750    | Train ACC: 98.06%    | Loss: 0.115\n",
      "[LOG] Epoch: 00800    | Train ACC: 98.06%    | Loss: 0.112\n",
      "[LOG] Epoch: 00850    | Train ACC: 98.06%    | Loss: 0.110\n",
      "[LOG] Epoch: 00900    | Train ACC: 98.06%    | Loss: 0.108\n",
      "[LOG] Epoch: 00950    | Train ACC: 98.06%    | Loss: 0.106\n",
      "[LOG] Epoch: 01000    | Train ACC: 98.06%    | Loss: 0.104\n",
      "[LOG] Epoch: 01050    | Train ACC: 98.06%    | Loss: 0.102\n",
      "[LOG] Epoch: 01100    | Train ACC: 98.06%    | Loss: 0.101\n",
      "[LOG] Epoch: 01150    | Train ACC: 98.06%    | Loss: 0.099\n",
      "[LOG] Epoch: 01200    | Train ACC: 98.06%    | Loss: 0.098\n",
      "[LOG] Epoch: 01250    | Train ACC: 98.06%    | Loss: 0.097\n",
      "[LOG] Epoch: 01300    | Train ACC: 98.06%    | Loss: 0.096\n",
      "[LOG] Epoch: 01350    | Train ACC: 98.06%    | Loss: 0.095\n",
      "[LOG] Epoch: 01400    | Train ACC: 98.06%    | Loss: 0.094\n",
      "[LOG] Epoch: 01450    | Train ACC: 98.06%    | Loss: 0.093\n",
      "[LOG] Epoch: 01500    | Train ACC: 98.06%    | Loss: 0.092\n",
      "[LOG] Epoch: 01550    | Train ACC: 98.24%    | Loss: 0.091\n",
      "[LOG] Epoch: 01600    | Train ACC: 98.24%    | Loss: 0.090\n",
      "[LOG] Epoch: 01650    | Train ACC: 98.59%    | Loss: 0.089\n",
      "[LOG] Epoch: 01700    | Train ACC: 98.59%    | Loss: 0.088\n",
      "[LOG] Epoch: 01750    | Train ACC: 98.59%    | Loss: 0.087\n",
      "[LOG] Epoch: 01800    | Train ACC: 98.59%    | Loss: 0.087\n",
      "[LOG] Epoch: 01850    | Train ACC: 98.59%    | Loss: 0.086\n",
      "[LOG] Epoch: 01900    | Train ACC: 98.59%    | Loss: 0.085\n",
      "[LOG] Epoch: 01950    | Train ACC: 98.59%    | Loss: 0.085\n",
      "[LOG] Epoch: 02000    | Train ACC: 98.59%    | Loss: 0.084\n",
      "[LOG] Epoch: 02050    | Train ACC: 98.59%    | Loss: 0.083\n",
      "[LOG] Epoch: 02100    | Train ACC: 98.59%    | Loss: 0.083\n",
      "[LOG] Epoch: 02150    | Train ACC: 98.59%    | Loss: 0.082\n",
      "[LOG] Epoch: 02200    | Train ACC: 98.59%    | Loss: 0.082\n",
      "[LOG] Epoch: 02250    | Train ACC: 98.59%    | Loss: 0.081\n",
      "[LOG] Epoch: 02300    | Train ACC: 98.59%    | Loss: 0.081\n",
      "[LOG] Epoch: 02350    | Train ACC: 98.59%    | Loss: 0.080\n",
      "[LOG] Epoch: 02400    | Train ACC: 98.59%    | Loss: 0.080\n",
      "[LOG] Epoch: 02450    | Train ACC: 98.59%    | Loss: 0.079\n",
      "[LOG] Epoch: 02500    | Train ACC: 98.59%    | Loss: 0.079\n",
      "[LOG] Epoch: 02550    | Train ACC: 98.59%    | Loss: 0.078\n",
      "[LOG] Epoch: 02600    | Train ACC: 98.59%    | Loss: 0.078\n",
      "[LOG] Epoch: 02650    | Train ACC: 98.59%    | Loss: 0.078\n",
      "[LOG] Epoch: 02700    | Train ACC: 98.59%    | Loss: 0.077\n",
      "[LOG] Epoch: 02750    | Train ACC: 98.59%    | Loss: 0.077\n",
      "[LOG] Epoch: 02800    | Train ACC: 98.59%    | Loss: 0.076\n",
      "[LOG] Epoch: 02850    | Train ACC: 98.59%    | Loss: 0.076\n",
      "[LOG] Epoch: 02900    | Train ACC: 98.59%    | Loss: 0.076\n",
      "[LOG] Epoch: 02950    | Train ACC: 98.59%    | Loss: 0.075\n",
      "[LOG] Epoch: 03000    | Train ACC: 98.59%    | Loss: 0.075\n",
      "[LOG] Epoch: 03050    | Train ACC: 98.59%    | Loss: 0.075\n",
      "[LOG] Epoch: 03100    | Train ACC: 98.59%    | Loss: 0.074\n",
      "[LOG] Epoch: 03150    | Train ACC: 98.59%    | Loss: 0.074\n",
      "[LOG] Epoch: 03200    | Train ACC: 98.59%    | Loss: 0.074\n",
      "[LOG] Epoch: 03250    | Train ACC: 98.59%    | Loss: 0.073\n",
      "[LOG] Epoch: 03300    | Train ACC: 98.59%    | Loss: 0.073\n",
      "[LOG] Epoch: 03350    | Train ACC: 98.59%    | Loss: 0.073\n",
      "[LOG] Epoch: 03400    | Train ACC: 98.59%    | Loss: 0.073\n",
      "[LOG] Epoch: 03450    | Train ACC: 98.59%    | Loss: 0.072\n",
      "[LOG] Epoch: 03500    | Train ACC: 98.59%    | Loss: 0.072\n",
      "[LOG] Epoch: 03550    | Train ACC: 98.59%    | Loss: 0.072\n",
      "[LOG] Epoch: 03600    | Train ACC: 98.59%    | Loss: 0.071\n",
      "[LOG] Epoch: 03650    | Train ACC: 98.59%    | Loss: 0.071\n",
      "[LOG] Epoch: 03700    | Train ACC: 98.59%    | Loss: 0.071\n",
      "[LOG] Epoch: 03750    | Train ACC: 98.59%    | Loss: 0.071\n",
      "[LOG] Epoch: 03800    | Train ACC: 98.59%    | Loss: 0.070\n",
      "[LOG] Epoch: 03850    | Train ACC: 98.59%    | Loss: 0.070\n",
      "[LOG] Epoch: 03900    | Train ACC: 98.59%    | Loss: 0.070\n",
      "[LOG] Epoch: 03950    | Train ACC: 98.59%    | Loss: 0.070\n",
      "[LOG] Epoch: 04000    | Train ACC: 98.59%    | Loss: 0.070\n",
      "[LOG] Epoch: 04050    | Train ACC: 98.59%    | Loss: 0.069\n",
      "[LOG] Epoch: 04100    | Train ACC: 98.59%    | Loss: 0.069\n",
      "[LOG] Epoch: 04150    | Train ACC: 98.59%    | Loss: 0.069\n",
      "[LOG] Epoch: 04200    | Train ACC: 98.59%    | Loss: 0.069\n",
      "[LOG] Epoch: 04250    | Train ACC: 98.59%    | Loss: 0.069\n",
      "[LOG] Epoch: 04300    | Train ACC: 98.59%    | Loss: 0.068\n",
      "[LOG] Epoch: 04350    | Train ACC: 98.59%    | Loss: 0.068\n",
      "[LOG] Epoch: 04400    | Train ACC: 98.59%    | Loss: 0.068\n",
      "[LOG] Epoch: 04450    | Train ACC: 98.59%    | Loss: 0.068\n",
      "[LOG] Epoch: 04500    | Train ACC: 98.59%    | Loss: 0.068\n",
      "[LOG] Epoch: 04550    | Train ACC: 98.59%    | Loss: 0.067\n",
      "[LOG] Epoch: 04600    | Train ACC: 98.59%    | Loss: 0.067\n",
      "[LOG] Epoch: 04650    | Train ACC: 98.59%    | Loss: 0.067\n",
      "[LOG] Epoch: 04700    | Train ACC: 98.59%    | Loss: 0.067\n",
      "[LOG] Epoch: 04750    | Train ACC: 98.59%    | Loss: 0.067\n",
      "[LOG] Epoch: 04800    | Train ACC: 98.59%    | Loss: 0.066\n",
      "[LOG] Epoch: 04850    | Train ACC: 98.59%    | Loss: 0.066\n",
      "[LOG] Epoch: 04900    | Train ACC: 98.59%    | Loss: 0.066\n",
      "[LOG] Epoch: 04950    | Train ACC: 98.59%    | Loss: 0.066\n",
      "[LOG] Epoch: 05000    | Train ACC: 98.59%    | Loss: 0.066\n",
      "[LOG] Epoch: 05050    | Train ACC: 98.59%    | Loss: 0.066\n",
      "[LOG] Epoch: 05100    | Train ACC: 98.59%    | Loss: 0.065\n",
      "[LOG] Epoch: 05150    | Train ACC: 98.59%    | Loss: 0.065\n",
      "[LOG] Epoch: 05200    | Train ACC: 98.59%    | Loss: 0.065\n",
      "[LOG] Epoch: 05250    | Train ACC: 98.59%    | Loss: 0.065\n",
      "[LOG] Epoch: 05300    | Train ACC: 98.59%    | Loss: 0.065\n",
      "[LOG] Epoch: 05350    | Train ACC: 98.59%    | Loss: 0.065\n",
      "[LOG] Epoch: 05400    | Train ACC: 98.59%    | Loss: 0.065\n",
      "[LOG] Epoch: 05450    | Train ACC: 98.59%    | Loss: 0.064\n",
      "[LOG] Epoch: 05500    | Train ACC: 98.59%    | Loss: 0.064\n",
      "[LOG] Epoch: 05550    | Train ACC: 98.59%    | Loss: 0.064\n",
      "[LOG] Epoch: 05600    | Train ACC: 98.59%    | Loss: 0.064\n",
      "[LOG] Epoch: 05650    | Train ACC: 98.59%    | Loss: 0.064\n",
      "[LOG] Epoch: 05700    | Train ACC: 98.59%    | Loss: 0.064\n",
      "[LOG] Epoch: 05750    | Train ACC: 98.59%    | Loss: 0.064\n",
      "[LOG] Epoch: 05800    | Train ACC: 98.59%    | Loss: 0.064\n",
      "[LOG] Epoch: 05850    | Train ACC: 98.59%    | Loss: 0.063\n",
      "[LOG] Epoch: 05900    | Train ACC: 98.59%    | Loss: 0.063\n",
      "[LOG] Epoch: 05950    | Train ACC: 98.59%    | Loss: 0.063\n",
      "[LOG] Epoch: 06000    | Train ACC: 98.59%    | Loss: 0.063\n",
      "[LOG] Epoch: 06050    | Train ACC: 98.59%    | Loss: 0.063\n",
      "[LOG] Epoch: 06100    | Train ACC: 98.59%    | Loss: 0.063\n",
      "[LOG] Epoch: 06150    | Train ACC: 98.59%    | Loss: 0.063\n",
      "[LOG] Epoch: 06200    | Train ACC: 98.59%    | Loss: 0.063\n",
      "[LOG] Epoch: 06250    | Train ACC: 98.59%    | Loss: 0.062\n",
      "[LOG] Epoch: 06300    | Train ACC: 98.59%    | Loss: 0.062\n",
      "[LOG] Epoch: 06350    | Train ACC: 98.59%    | Loss: 0.062\n",
      "[LOG] Epoch: 06400    | Train ACC: 98.59%    | Loss: 0.062\n",
      "[LOG] Epoch: 06450    | Train ACC: 98.59%    | Loss: 0.062\n",
      "[LOG] Epoch: 06500    | Train ACC: 98.59%    | Loss: 0.062\n",
      "[LOG] Epoch: 06550    | Train ACC: 98.59%    | Loss: 0.062\n",
      "[LOG] Epoch: 06600    | Train ACC: 98.59%    | Loss: 0.062\n",
      "[LOG] Epoch: 06650    | Train ACC: 98.59%    | Loss: 0.062\n",
      "[LOG] Epoch: 06700    | Train ACC: 98.59%    | Loss: 0.061\n",
      "[LOG] Epoch: 06750    | Train ACC: 98.59%    | Loss: 0.061\n",
      "[LOG] Epoch: 06800    | Train ACC: 98.59%    | Loss: 0.061\n",
      "[LOG] Epoch: 06850    | Train ACC: 98.59%    | Loss: 0.061\n",
      "[LOG] Epoch: 06900    | Train ACC: 98.59%    | Loss: 0.061\n",
      "[LOG] Epoch: 06950    | Train ACC: 98.59%    | Loss: 0.061\n",
      "[LOG] Epoch: 07000    | Train ACC: 98.59%    | Loss: 0.061\n",
      "[LOG] Epoch: 07050    | Train ACC: 98.59%    | Loss: 0.061\n",
      "[LOG] Epoch: 07100    | Train ACC: 98.59%    | Loss: 0.061\n",
      "[LOG] Epoch: 07150    | Train ACC: 98.59%    | Loss: 0.061\n",
      "[LOG] Epoch: 07200    | Train ACC: 98.59%    | Loss: 0.060\n",
      "[LOG] Epoch: 07250    | Train ACC: 98.59%    | Loss: 0.060\n",
      "[LOG] Epoch: 07300    | Train ACC: 98.59%    | Loss: 0.060\n",
      "[LOG] Epoch: 07350    | Train ACC: 98.59%    | Loss: 0.060\n",
      "[LOG] Epoch: 07400    | Train ACC: 98.59%    | Loss: 0.060\n",
      "[LOG] Epoch: 07450    | Train ACC: 98.59%    | Loss: 0.060\n",
      "[LOG] Epoch: 07500    | Train ACC: 98.59%    | Loss: 0.060\n",
      "[LOG] Epoch: 07550    | Train ACC: 98.59%    | Loss: 0.060\n",
      "[LOG] Epoch: 07600    | Train ACC: 98.59%    | Loss: 0.060\n",
      "[LOG] Epoch: 07650    | Train ACC: 98.59%    | Loss: 0.060\n",
      "[LOG] Epoch: 07700    | Train ACC: 98.59%    | Loss: 0.060\n",
      "[LOG] Epoch: 07750    | Train ACC: 98.59%    | Loss: 0.059\n",
      "[LOG] Epoch: 07800    | Train ACC: 98.59%    | Loss: 0.059\n",
      "[LOG] Epoch: 07850    | Train ACC: 98.59%    | Loss: 0.059\n",
      "[LOG] Epoch: 07900    | Train ACC: 98.59%    | Loss: 0.059\n",
      "[LOG] Epoch: 07950    | Train ACC: 98.59%    | Loss: 0.059\n",
      "[LOG] Epoch: 08000    | Train ACC: 98.59%    | Loss: 0.059\n",
      "[LOG] Epoch: 08050    | Train ACC: 98.59%    | Loss: 0.059\n",
      "[LOG] Epoch: 08100    | Train ACC: 98.59%    | Loss: 0.059\n",
      "[LOG] Epoch: 08150    | Train ACC: 98.59%    | Loss: 0.059\n",
      "[LOG] Epoch: 08200    | Train ACC: 98.59%    | Loss: 0.059\n",
      "[LOG] Epoch: 08250    | Train ACC: 98.59%    | Loss: 0.059\n",
      "[LOG] Epoch: 08300    | Train ACC: 98.59%    | Loss: 0.059\n",
      "[LOG] Epoch: 08350    | Train ACC: 98.59%    | Loss: 0.058\n",
      "[LOG] Epoch: 08400    | Train ACC: 98.59%    | Loss: 0.058\n",
      "[LOG] Epoch: 08450    | Train ACC: 98.59%    | Loss: 0.058\n",
      "[LOG] Epoch: 08500    | Train ACC: 98.59%    | Loss: 0.058\n",
      "[LOG] Epoch: 08550    | Train ACC: 98.59%    | Loss: 0.058\n",
      "[LOG] Epoch: 08600    | Train ACC: 98.59%    | Loss: 0.058\n",
      "[LOG] Epoch: 08650    | Train ACC: 98.59%    | Loss: 0.058\n",
      "[LOG] Epoch: 08700    | Train ACC: 98.59%    | Loss: 0.058\n",
      "[LOG] Epoch: 08750    | Train ACC: 98.59%    | Loss: 0.058\n",
      "[LOG] Epoch: 08800    | Train ACC: 98.59%    | Loss: 0.058\n",
      "[LOG] Epoch: 08850    | Train ACC: 98.59%    | Loss: 0.058\n",
      "[LOG] Epoch: 08900    | Train ACC: 98.59%    | Loss: 0.058\n",
      "[LOG] Epoch: 08950    | Train ACC: 98.59%    | Loss: 0.058\n",
      "[LOG] Epoch: 09000    | Train ACC: 98.59%    | Loss: 0.058\n",
      "[LOG] Epoch: 09050    | Train ACC: 98.59%    | Loss: 0.057\n",
      "[LOG] Epoch: 09100    | Train ACC: 98.59%    | Loss: 0.057\n",
      "[LOG] Epoch: 09150    | Train ACC: 98.59%    | Loss: 0.057\n",
      "[LOG] Epoch: 09200    | Train ACC: 98.59%    | Loss: 0.057\n",
      "[LOG] Epoch: 09250    | Train ACC: 98.59%    | Loss: 0.057\n",
      "[LOG] Epoch: 09300    | Train ACC: 98.59%    | Loss: 0.057\n",
      "[LOG] Epoch: 09350    | Train ACC: 98.59%    | Loss: 0.057\n",
      "[LOG] Epoch: 09400    | Train ACC: 98.59%    | Loss: 0.057\n",
      "[LOG] Epoch: 09450    | Train ACC: 98.59%    | Loss: 0.057\n",
      "[LOG] Epoch: 09500    | Train ACC: 98.59%    | Loss: 0.057\n",
      "[LOG] Epoch: 09550    | Train ACC: 98.59%    | Loss: 0.057\n",
      "[LOG] Epoch: 09600    | Train ACC: 98.59%    | Loss: 0.057\n",
      "[LOG] Epoch: 09650    | Train ACC: 98.59%    | Loss: 0.057\n",
      "[LOG] Epoch: 09700    | Train ACC: 98.59%    | Loss: 0.057\n",
      "[LOG] Epoch: 09750    | Train ACC: 98.59%    | Loss: 0.057\n",
      "[LOG] Epoch: 09800    | Train ACC: 98.59%    | Loss: 0.056\n",
      "[LOG] Epoch: 09850    | Train ACC: 98.59%    | Loss: 0.056\n",
      "[LOG] Epoch: 09900    | Train ACC: 98.59%    | Loss: 0.056\n",
      "[LOG] Epoch: 09950    | Train ACC: 98.59%    | Loss: 0.056\n",
      "[LOG] Epoch: 10000    | Train ACC: 98.59%    | Loss: 0.056\n"
     ]
    }
   ],
   "source": [
    "# training process\n",
    "final_model, recorded = Training(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744f73c9",
   "metadata": {},
   "source": [
    "Model parameters after training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d91ac62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:\n",
      "  | Weights: Parameter containing:\n",
      "tensor([[ 0.1430,  0.0843,  0.5500,  0.7319,  0.5261,  0.5725,  0.2357, -0.1939,\n",
      "          0.6098,  0.7666,  0.0987, -0.4705,  0.8832,  0.0144,  0.6301,  0.7085,\n",
      "          0.1324, -0.5539, -0.0399,  0.2225, -0.2198, -0.5947,  0.7533,  1.0899,\n",
      "          0.6774,  0.7159,  0.8328,  0.0684,  0.7457,  0.8711,  0.7905]],\n",
      "       requires_grad=True)\n",
      "  | Bias: Parameter containing:\n",
      "tensor([-0.1261], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('Model parameters:')\n",
    "print('  | Weights: %s' % final_model.linear.weight)\n",
    "print('  | Bias: %s'    % final_model.linear.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4b934d",
   "metadata": {},
   "source": [
    "### Virtualize record of training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f6c2519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_graphs(diagnosis_title, record):\n",
    "    accuracies, losses = record\n",
    "    plt.plot(losses)\n",
    "    plt.title(f\"{diagnosis_title} - Training Loss\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Training Loss\")\n",
    "    plt.show()\n",
    "    plt.plot(accuracies)\n",
    "    plt.title(f\"{diagnosis_title} - Training Accuracy\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Training Accuracy (Percent %)\")\n",
    "    plt.show()\n",
    "\n",
    "diagnosis_title = 'Breast cancer'\n",
    "plot_graphs(diagnosis_title, recorded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf25b7",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f90ff66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Testing Accuracy = 96.49%\n"
     ]
    }
   ],
   "source": [
    "test_acc = compute_accuracy(final_model, X_test, Y_test)\n",
    "print('[+] Testing Accuracy = {}'.format(to_percent(test_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09624fec",
   "metadata": {},
   "source": [
    "We actually train the machine learning model to diagnose the Breast cancer. As you can see in the graphs, the training loss drops quickly to almost zero and the training accuracy reaches the 98%. The testing accuracy is also 94.74. Notice that this machine learning system diagnoses this disease in a perfect way; whereas human doctors can commit mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49831ce4",
   "metadata": {},
   "source": [
    "## Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7492c434",
   "metadata": {},
   "source": [
    "So far, we have used machine learning in an insecure way. Now, we introduce our proposed encrypted learning model. This is a combination of federated learning and homomorphic encryption!\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='images/encrypted_learning.png'>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42c78dc",
   "metadata": {},
   "source": [
    "**Set up**\n",
    "\n",
    "- 1. Define HE scheme, Hospitals shared a HE private key, and share with the Aggregator a public key.\n",
    "- 2. Define the model that use to train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a88fe",
   "metadata": {},
   "source": [
    "**Local training**\n",
    "- 3. Hospitals train locally with the model in plaintext, extract model updates (the final weights) and encrypt them using the private HE key.\n",
    "- 4. Each hospital sends its encrypted model's weights to the Aggregator (untrusted)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e462933f",
   "metadata": {},
   "source": [
    "**Global model weight aggregator**\n",
    "- 5. Aggregator uses its public key to perform homomorphic operation on the encrypted weights to obtain new encrypted model, and send its to hospitals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8648dec4",
   "metadata": {},
   "source": [
    "**Repeated**\n",
    "- 6. Each hospital receives the decrypted model, then uses their private HE key, decrypts its to get the new model.\n",
    "- 7. This process ís repeated until hospitals find the new desired model or after a termination criteria is met."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e13ec8",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30edbdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa8cfc",
   "metadata": {},
   "source": [
    "### Dataset 1\n",
    "\n",
    "[source](https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset)\n",
    "\n",
    "**Description:**\n",
    "Breast cancer is the most common cancer amongst women in the world. It accounts for 25% of all cancer cases, and affected over 2.1 Million people in 2015 alone. It starts when cells in the breast begin to grow out of control. These cells usually form tumors that can be seen via X-ray or felt as lumps in the breast area.\n",
    "\n",
    "The key challenges against it’s detection is how to classify tumors into malignant (cancerous) or benign(non cancerous). We ask you to complete the analysis of classifying these tumors using machine learning (with SVMs) and the Breast Cancer Wisconsin (Diagnostic) Dataset.\n",
    "\n",
    "**Acknowledgements:**\n",
    "This dataset has been referred from Kaggle.\n",
    "\n",
    "**Objective:**\n",
    "* Understand the Dataset & cleanup (if required).\n",
    "* Build classification models to predict whether the cancer type is Malignant or Benign.\n",
    "* Also fine-tune the hyperparameters & compare the evaluation metrics of various classification algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4647fb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1202, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_pts_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_pts_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dim_worst</th>\n",
       "      <th>diagnostic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>561</td>\n",
       "      <td>20.47</td>\n",
       "      <td>20.67</td>\n",
       "      <td>134.70</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.09156</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.15230</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>...</td>\n",
       "      <td>27.15</td>\n",
       "      <td>152.00</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>0.1097</td>\n",
       "      <td>0.25340</td>\n",
       "      <td>0.30920</td>\n",
       "      <td>0.16130</td>\n",
       "      <td>0.3220</td>\n",
       "      <td>0.06386</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>11.75</td>\n",
       "      <td>20.18</td>\n",
       "      <td>76.10</td>\n",
       "      <td>419.8</td>\n",
       "      <td>0.10890</td>\n",
       "      <td>0.11410</td>\n",
       "      <td>0.06843</td>\n",
       "      <td>0.03738</td>\n",
       "      <td>0.1993</td>\n",
       "      <td>...</td>\n",
       "      <td>26.21</td>\n",
       "      <td>88.91</td>\n",
       "      <td>543.9</td>\n",
       "      <td>0.1358</td>\n",
       "      <td>0.18920</td>\n",
       "      <td>0.19560</td>\n",
       "      <td>0.07909</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.07987</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151</td>\n",
       "      <td>13.77</td>\n",
       "      <td>13.27</td>\n",
       "      <td>88.06</td>\n",
       "      <td>582.7</td>\n",
       "      <td>0.09198</td>\n",
       "      <td>0.06221</td>\n",
       "      <td>0.01063</td>\n",
       "      <td>0.01917</td>\n",
       "      <td>0.1592</td>\n",
       "      <td>...</td>\n",
       "      <td>16.93</td>\n",
       "      <td>94.17</td>\n",
       "      <td>661.1</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0.03732</td>\n",
       "      <td>0.05802</td>\n",
       "      <td>0.2823</td>\n",
       "      <td>0.06794</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>231</td>\n",
       "      <td>12.34</td>\n",
       "      <td>14.95</td>\n",
       "      <td>78.29</td>\n",
       "      <td>469.1</td>\n",
       "      <td>0.08682</td>\n",
       "      <td>0.04571</td>\n",
       "      <td>0.02109</td>\n",
       "      <td>0.02054</td>\n",
       "      <td>0.1571</td>\n",
       "      <td>...</td>\n",
       "      <td>16.85</td>\n",
       "      <td>84.11</td>\n",
       "      <td>533.1</td>\n",
       "      <td>0.1048</td>\n",
       "      <td>0.06744</td>\n",
       "      <td>0.04921</td>\n",
       "      <td>0.04793</td>\n",
       "      <td>0.2298</td>\n",
       "      <td>0.05974</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>410</td>\n",
       "      <td>13.80</td>\n",
       "      <td>15.79</td>\n",
       "      <td>90.43</td>\n",
       "      <td>584.1</td>\n",
       "      <td>0.10070</td>\n",
       "      <td>0.12800</td>\n",
       "      <td>0.07789</td>\n",
       "      <td>0.05069</td>\n",
       "      <td>0.1662</td>\n",
       "      <td>...</td>\n",
       "      <td>20.86</td>\n",
       "      <td>110.30</td>\n",
       "      <td>812.4</td>\n",
       "      <td>0.1411</td>\n",
       "      <td>0.35420</td>\n",
       "      <td>0.27790</td>\n",
       "      <td>0.13830</td>\n",
       "      <td>0.2589</td>\n",
       "      <td>0.10300</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0  561        20.47         20.67          134.70     1299.0          0.09156   \n",
       "1   77        11.75         20.18           76.10      419.8          0.10890   \n",
       "2  151        13.77         13.27           88.06      582.7          0.09198   \n",
       "3  231        12.34         14.95           78.29      469.1          0.08682   \n",
       "4  410        13.80         15.79           90.43      584.1          0.10070   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave_pts_mean  symmetry_mean  ...  \\\n",
       "0           0.13130         0.15230           0.10150         0.2166  ...   \n",
       "1           0.11410         0.06843           0.03738         0.1993  ...   \n",
       "2           0.06221         0.01063           0.01917         0.1592  ...   \n",
       "3           0.04571         0.02109           0.02054         0.1571  ...   \n",
       "4           0.12800         0.07789           0.05069         0.1662  ...   \n",
       "\n",
       "   texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0          27.15           152.00      1645.0            0.1097   \n",
       "1          26.21            88.91       543.9            0.1358   \n",
       "2          16.93            94.17       661.1            0.1170   \n",
       "3          16.85            84.11       533.1            0.1048   \n",
       "4          20.86           110.30       812.4            0.1411   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave_pts_worst  symmetry_worst  \\\n",
       "0            0.25340          0.30920            0.16130          0.3220   \n",
       "1            0.18920          0.19560            0.07909          0.3168   \n",
       "2            0.10720          0.03732            0.05802          0.2823   \n",
       "3            0.06744          0.04921            0.04793          0.2298   \n",
       "4            0.35420          0.27790            0.13830          0.2589   \n",
       "\n",
       "   fractal_dim_worst  diagnostic  \n",
       "0            0.06386           M  \n",
       "1            0.07987           B  \n",
       "2            0.06794           B  \n",
       "3            0.05974           B  \n",
       "4            0.10300           M  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('data/dataset1.csv')\n",
    "print(\"Shape:\", df1.shape)\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32f3373",
   "metadata": {},
   "source": [
    "### Dataset 2\n",
    "\n",
    "[source](https://www.kaggle.com/code/a3amat02/breast-cancer-classification/input)\n",
    "\n",
    "**About this file**\n",
    "\n",
    "* y. The outcomes. A factor with two levels denoting whether a mass is malignant (\"M\") or benign (\"B\").\n",
    "* x. The predictors. A matrix with the mean, standard error and worst value of each of 10 nuclear measurements on the slide, for 30 total features per biopsy:\n",
    "* radius. Nucleus radius (mean of distances from center to points on perimeter).\n",
    "* texture. Nucleus texture (standard deviation of grayscale values).\n",
    "* perimeter. Nucleus perimeter.\n",
    "* area. Nucleus area.\n",
    "* smoothness. Nucleus smoothness (local variation in radius lengths).\n",
    "* compactness. Nucleus compactness (perimeter^2/area - 1).\n",
    "* concavity, Nucleus concavity (severity of concave portions of the contour).\n",
    "* concave_pts. Number of concave portions of the nucleus contour.\n",
    "* symmetry. Nucleus symmetry.\n",
    "* fractal_dim. Nucleus fractal dimension (\"coastline approximation\" -1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "324d6157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1193, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_pts_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_pts_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dim_worst</th>\n",
       "      <th>diagnostic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>374</td>\n",
       "      <td>14.68</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.073950</td>\n",
       "      <td>0.052590</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>...</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.14640</td>\n",
       "      <td>0.18710</td>\n",
       "      <td>0.29140</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>325</td>\n",
       "      <td>12.34</td>\n",
       "      <td>12.27</td>\n",
       "      <td>78.94</td>\n",
       "      <td>468.5</td>\n",
       "      <td>0.09003</td>\n",
       "      <td>0.06307</td>\n",
       "      <td>0.029580</td>\n",
       "      <td>0.026470</td>\n",
       "      <td>0.1689</td>\n",
       "      <td>...</td>\n",
       "      <td>19.27</td>\n",
       "      <td>87.22</td>\n",
       "      <td>564.9</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.20740</td>\n",
       "      <td>0.17910</td>\n",
       "      <td>0.10700</td>\n",
       "      <td>0.3110</td>\n",
       "      <td>0.07592</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>359</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.070170</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.24160</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264</td>\n",
       "      <td>14.80</td>\n",
       "      <td>17.66</td>\n",
       "      <td>95.88</td>\n",
       "      <td>674.8</td>\n",
       "      <td>0.09179</td>\n",
       "      <td>0.08890</td>\n",
       "      <td>0.040690</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.1893</td>\n",
       "      <td>...</td>\n",
       "      <td>22.74</td>\n",
       "      <td>105.90</td>\n",
       "      <td>829.5</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.18810</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.08308</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.07285</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161</td>\n",
       "      <td>13.50</td>\n",
       "      <td>12.71</td>\n",
       "      <td>85.69</td>\n",
       "      <td>566.2</td>\n",
       "      <td>0.07376</td>\n",
       "      <td>0.03614</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>0.004419</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>...</td>\n",
       "      <td>16.94</td>\n",
       "      <td>95.48</td>\n",
       "      <td>698.7</td>\n",
       "      <td>0.09023</td>\n",
       "      <td>0.05836</td>\n",
       "      <td>0.01379</td>\n",
       "      <td>0.02210</td>\n",
       "      <td>0.2267</td>\n",
       "      <td>0.06192</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0  374        14.68         20.13           94.74      684.5          0.09867   \n",
       "1  325        12.34         12.27           78.94      468.5          0.09003   \n",
       "2  359        20.57         17.77          132.90     1326.0          0.08474   \n",
       "3  264        14.80         17.66           95.88      674.8          0.09179   \n",
       "4  161        13.50         12.71           85.69      566.2          0.07376   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave_pts_mean  symmetry_mean  ...  \\\n",
       "0           0.07200        0.073950          0.052590         0.1586  ...   \n",
       "1           0.06307        0.029580          0.026470         0.1689  ...   \n",
       "2           0.07864        0.086900          0.070170         0.1812  ...   \n",
       "3           0.08890        0.040690          0.022600         0.1893  ...   \n",
       "4           0.03614        0.002758          0.004419         0.1365  ...   \n",
       "\n",
       "   texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0          30.88           123.40      1138.0           0.14640   \n",
       "1          19.27            87.22       564.9           0.12920   \n",
       "2          23.41           158.80      1956.0           0.12380   \n",
       "3          22.74           105.90       829.5           0.12260   \n",
       "4          16.94            95.48       698.7           0.09023   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave_pts_worst  symmetry_worst  \\\n",
       "0            0.18710          0.29140            0.16090          0.3029   \n",
       "1            0.20740          0.17910            0.10700          0.3110   \n",
       "2            0.18660          0.24160            0.18600          0.2750   \n",
       "3            0.18810          0.20600            0.08308          0.3600   \n",
       "4            0.05836          0.01379            0.02210          0.2267   \n",
       "\n",
       "   fractal_dim_worst  diagnostic  \n",
       "0            0.08216           M  \n",
       "1            0.07592           B  \n",
       "2            0.08902           M  \n",
       "3            0.07285           B  \n",
       "4            0.06192           B  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('data/dataset2.csv')\n",
    "print(\"Shape:\", df2.shape)\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebe8356",
   "metadata": {},
   "source": [
    "### Dataset 3\n",
    "\n",
    "[source](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic))\n",
    "\n",
    "**Data Set Information:**\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. A few of the images can be found at [Web Link]\n",
    "\n",
    "Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.\n",
    "\n",
    "The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
    "\n",
    "This database is also available through the UW CS ftp server:\n",
    "ftp ftp.cs.wisc.edu\n",
    "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
    "\n",
    "\n",
    "**Attribute Information:**\n",
    "\n",
    "1) ID number\n",
    "\n",
    "2) Diagnosis (M = malignant, B = benign)\n",
    "\n",
    "3-32)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter)\n",
    "\n",
    "b) texture (standard deviation of gray-scale values)\n",
    "\n",
    "c) perimeter\n",
    "\n",
    "d) area\n",
    "\n",
    "e) smoothness (local variation in radius lengths)\n",
    "\n",
    "f) compactness (perimeter^2 / area - 1.0)\n",
    "\n",
    "g) concavity (severity of concave portions of the contour)\n",
    "\n",
    "h) concave points (number of concave portions of the contour)\n",
    "\n",
    "i) symmetry\n",
    "\n",
    "j) fractal dimension (\"coastline approximation\" - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acb6ee1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1189, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_pts_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_pts_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dim_worst</th>\n",
       "      <th>diagnostic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>529</td>\n",
       "      <td>15.49</td>\n",
       "      <td>19.97</td>\n",
       "      <td>102.40</td>\n",
       "      <td>744.7</td>\n",
       "      <td>0.11600</td>\n",
       "      <td>0.15620</td>\n",
       "      <td>0.18910</td>\n",
       "      <td>0.09113</td>\n",
       "      <td>0.1929</td>\n",
       "      <td>...</td>\n",
       "      <td>29.41</td>\n",
       "      <td>142.10</td>\n",
       "      <td>1359.0</td>\n",
       "      <td>0.1681</td>\n",
       "      <td>0.3913</td>\n",
       "      <td>0.55530</td>\n",
       "      <td>0.21210</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.10190</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.26780</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>447</td>\n",
       "      <td>13.43</td>\n",
       "      <td>19.63</td>\n",
       "      <td>85.84</td>\n",
       "      <td>565.4</td>\n",
       "      <td>0.09048</td>\n",
       "      <td>0.06288</td>\n",
       "      <td>0.05858</td>\n",
       "      <td>0.03438</td>\n",
       "      <td>0.1598</td>\n",
       "      <td>...</td>\n",
       "      <td>29.87</td>\n",
       "      <td>116.60</td>\n",
       "      <td>993.6</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.1546</td>\n",
       "      <td>0.26440</td>\n",
       "      <td>0.11600</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.07371</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>12.77</td>\n",
       "      <td>29.43</td>\n",
       "      <td>81.35</td>\n",
       "      <td>507.9</td>\n",
       "      <td>0.08276</td>\n",
       "      <td>0.04234</td>\n",
       "      <td>0.01997</td>\n",
       "      <td>0.01499</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>...</td>\n",
       "      <td>36.00</td>\n",
       "      <td>88.10</td>\n",
       "      <td>594.7</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.1064</td>\n",
       "      <td>0.08653</td>\n",
       "      <td>0.06498</td>\n",
       "      <td>0.2407</td>\n",
       "      <td>0.06484</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>12.00</td>\n",
       "      <td>15.65</td>\n",
       "      <td>76.95</td>\n",
       "      <td>443.3</td>\n",
       "      <td>0.09723</td>\n",
       "      <td>0.07165</td>\n",
       "      <td>0.04151</td>\n",
       "      <td>0.01863</td>\n",
       "      <td>0.2079</td>\n",
       "      <td>...</td>\n",
       "      <td>24.90</td>\n",
       "      <td>87.78</td>\n",
       "      <td>567.9</td>\n",
       "      <td>0.1377</td>\n",
       "      <td>0.2003</td>\n",
       "      <td>0.22670</td>\n",
       "      <td>0.07632</td>\n",
       "      <td>0.3379</td>\n",
       "      <td>0.07924</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0  529        15.49         19.97          102.40      744.7          0.11600   \n",
       "1  365        13.71         20.83           90.20      577.9          0.11890   \n",
       "2  447        13.43         19.63           85.84      565.4          0.09048   \n",
       "3  347        12.77         29.43           81.35      507.9          0.08276   \n",
       "4   27        12.00         15.65           76.95      443.3          0.09723   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave_pts_mean  symmetry_mean  ...  \\\n",
       "0           0.15620         0.18910           0.09113         0.1929  ...   \n",
       "1           0.16450         0.09366           0.05985         0.2196  ...   \n",
       "2           0.06288         0.05858           0.03438         0.1598  ...   \n",
       "3           0.04234         0.01997           0.01499         0.1539  ...   \n",
       "4           0.07165         0.04151           0.01863         0.2079  ...   \n",
       "\n",
       "   texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0          29.41           142.10      1359.0            0.1681   \n",
       "1          28.14           110.60       897.0            0.1654   \n",
       "2          29.87           116.60       993.6            0.1401   \n",
       "3          36.00            88.10       594.7            0.1234   \n",
       "4          24.90            87.78       567.9            0.1377   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave_pts_worst  symmetry_worst  \\\n",
       "0             0.3913          0.55530            0.21210          0.3187   \n",
       "1             0.3682          0.26780            0.15560          0.3196   \n",
       "2             0.1546          0.26440            0.11600          0.2884   \n",
       "3             0.1064          0.08653            0.06498          0.2407   \n",
       "4             0.2003          0.22670            0.07632          0.3379   \n",
       "\n",
       "   fractal_dim_worst  diagnostic  \n",
       "0            0.10190           M  \n",
       "1            0.11510           M  \n",
       "2            0.07371           M  \n",
       "3            0.06484           B  \n",
       "4            0.07924           B  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv('data/dataset3.csv')\n",
    "print(\"Shape:\", df3.shape)\n",
    "df3.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc06478",
   "metadata": {},
   "source": [
    "In this demo, there are 3 hospitals (with corresponding datasets above) but there could be more hospitals. The 3 hospitals cannot share the cases of their patients because they are competitors and it is necessary to protect the privacy of patients. Hence, the ML model will be learned in a federated way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eceeb3f",
   "metadata": {},
   "source": [
    "## Clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b814944",
   "metadata": {},
   "source": [
    "Import openFHE library. Then run `generate_key()`, this is just a python wrapper to run `openfhe-lib/build/key_gen`. After running this files, it will create `openfhe-lib/data` folder that holds:\n",
    "- `crypto_context.txt` : contain CKKS CryptoContext object\n",
    "- `public_key.txt`     : contain CKKS public key\n",
    "- `private_key.txt`    : contain CKKS private key\n",
    "- `mult_key.txt`       : contain CKKS multiplication key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c90acd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "from phe_lib.phe import * \n",
    "\n",
    "# === Generate Key-pairs of CKKS Context ===\n",
    "generate_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efbea12",
   "metadata": {},
   "source": [
    "First, we start by creating the `Client` class that simulate the computers of each hospital. This just rewrite the Logistic Regression process that we have implemented previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "00ea04a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, name, data_url, enc_file, n_features, iters):\n",
    "        self.id = name\n",
    "        self.enc_file = enc_file  # place wher clients save encrypted weights\n",
    "        \n",
    "        # split data into train and test\n",
    "        self.X_train, self.Y_train, self.X_test, self.Y_test = self.preprocessing(data_url)\n",
    "        \n",
    "        # define local training model\n",
    "        self.local_model = LogisticRegression(n_features)\n",
    "        \n",
    "        # some helpfull stuffs\n",
    "        self.decide_vectorized = np.vectorize(self.decide)\n",
    "        self.to_percent = lambda x: '{:.2f}%'.format(x)\n",
    "        self.num_epochs = iters\n",
    "        self.accuracies = []\n",
    "        self.losses = []\n",
    "        \n",
    "    def preprocessing(self, data_url):\n",
    "        df = pd.read_csv(data_url)\n",
    "        # Replace \"M\" with 1 and \"B\" with 0 at \"diagnostic\" column\n",
    "        df[\"diagnostic\"] = (df[\"diagnostic\"] == \"M\").astype(int)\n",
    "        \n",
    "        # split dataframe to train and test df\n",
    "        df_train, df_test = np.split(df.sample(frac=1), [int(0.8 * len(df))])\n",
    "        \n",
    "        # scaling and convert to tensor context\n",
    "        train, X_train, Y_train = scale_dataset(df_train, True)\n",
    "        test , X_test , Y_test  = scale_dataset(df_test , False)\n",
    "        return X_train, Y_train, X_test, Y_test\n",
    "    \n",
    "    def decide(self, y):\n",
    "        return 1. if y >= 0.5 else 0.\n",
    "    \n",
    "    def compute_accuracy(self, input, output):\n",
    "        prediction = self.local_model(input).data.numpy()[:, 0]\n",
    "        n_samples = prediction.shape[0] + 0.\n",
    "        prediction = self.decide_vectorized(prediction)\n",
    "        equal = prediction == output.data.numpy()\n",
    "        return 100. * equal.sum() / n_samples\n",
    "    \n",
    "    def local_training(self, debug=True):\n",
    "        n_samples, _ = self.X_train.shape\n",
    "\n",
    "        # define criterion function and set up optimizer\n",
    "        criterion = torch.nn.BCELoss(reduction='mean')\n",
    "        optimizer = torch.optim.SGD(self.local_model.parameters(), lr=0.01)  \n",
    "\n",
    "        # main process\n",
    "        for epoch in range(self.num_epochs):  \n",
    "            optimizer.zero_grad()\n",
    "            #### Compute outputs ####\n",
    "            prediction = self.local_model(self.X_train)\n",
    "\n",
    "            #### Compute gradients ####\n",
    "            loss = criterion(prediction.squeeze(), self.Y_train)\n",
    "            loss.backward()\n",
    "\n",
    "            #### Update weights #### \n",
    "            optimizer.step()\n",
    "\n",
    "            # compute accuracy and loss\n",
    "            train_acc = self.compute_accuracy(self.X_train, self.Y_train)\n",
    "            train_loss = loss.item()\n",
    "                \n",
    "            self.losses.append(train_loss)\n",
    "            self.accuracies.append(train_acc)\n",
    "        \n",
    "            #### Logging ####\n",
    "            if debug and (epoch + 1)%50 == 0:\n",
    "                print('[LOG] Epoch: %05d' % (epoch + 1), end=\"\")\n",
    "                print('    | Train ACC: %s' % self.to_percent(train_acc), end=\"\")\n",
    "                print('    | Loss: %.3f' % train_loss)\n",
    "    \n",
    "    def encrypted_model_params(self):\n",
    "        model_weights = self.local_model.linear.weight.data.squeeze().tolist()\n",
    "        model_bias    = self.local_model.linear.bias.data.squeeze().tolist()\n",
    "        \n",
    "        model_params  = model_weights + [model_bias]\n",
    "        encrypt_weights(model_params, self.enc_file)\n",
    "        \n",
    "    def decrypted_model_params(self):\n",
    "        params = decrypt_weights(\"/enc_aggregator_weight_server.txt\")\n",
    "        # convert float to tensor context\n",
    "        W = Variable(torch.tensor([params[:-1]], dtype = torch.float32))\n",
    "        B = Variable(torch.tensor( params[-1], dtype = torch.float32))\n",
    "        \n",
    "        self.local_model.linear.weight = nn.Parameter(W)\n",
    "        self.local_model.linear.bias   = nn.Parameter(B)\n",
    "    \n",
    "    def plot_graphs(self, diagnosis_title = 'Breast cancer'):\n",
    "        plt.plot(self.losses)\n",
    "        plt.title(f\"{diagnosis_title} - Training Loss\")\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Training Loss\")\n",
    "        plt.show()\n",
    "        plt.plot(self.accuracies)\n",
    "        plt.title(f\"{diagnosis_title} - Training Accuracy\")\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Training Accuracy (Percent %)\")\n",
    "        plt.show()\n",
    "    \n",
    "    def print_result_after_training(self):\n",
    "        print('Model parameters:')\n",
    "        print('  | Weights: %s' % self.local_model.linear.weight)\n",
    "        print('  | Bias: %s' % self.local_model.linear.bias)\n",
    "        self.plot_graphs()\n",
    "    \n",
    "    def evaluating_model(self):\n",
    "        test_acc = self.compute_accuracy(self.X_test, self.Y_test)\n",
    "        print('[+] Testing Accuracy = {}'.format(self.to_percent(test_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d0e24f",
   "metadata": {},
   "source": [
    "## Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586569f",
   "metadata": {},
   "source": [
    "We define some functions to train the machine learning model in a federated way while keeping track of the training loss and the training accuracy, for each hospital separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9eaeed15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fanyo/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/home/fanyo/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/home/fanyo/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "/home/fanyo/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "clients = [\n",
    "    Client('Hostpital1', 'data/dataset1.csv', \"/enc_weight_client1.txt\", n_features=31, iters=10), \n",
    "    Client('Hostpital2', 'data/dataset2.csv', \"/enc_weight_client2.txt\", n_features=31, iters=10),\n",
    "    Client('Hostpital3', 'data/dataset3.csv', \"/enc_weight_client3.txt\", n_features=31, iters=10),\n",
    "    Client('Hostpital4', 'data/dataset4.csv', \"/enc_weight_client4.txt\", n_features=31, iters=10)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa622e2b",
   "metadata": {},
   "source": [
    "The whole process is done in a server aggregator, in 1000 iterations (we can vary the number of iterations.) At each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "25d8335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 1000 #2000\n",
    "worker_iterations = 5\n",
    "to_percent = lambda x: '{:.2f}%'.format(x)\n",
    "n_hospitals = len(clients)\n",
    "n_features = 31\n",
    "    \n",
    "def compute_federated_accuracy(model, input, output):\n",
    "    prediction = model(input)\n",
    "    n_samples = prediction.shape[0]\n",
    "    s = 0.\n",
    "    for i in range(n_samples):\n",
    "        p = 1. if prediction[i] >= 0.5 else 0.\n",
    "        e = 1. if p == output[i] else 0.\n",
    "        s += e\n",
    "    return 100. * s / n_samples\n",
    "\n",
    "def federated_learning(clients):\n",
    "    # init global training model\n",
    "    global_model = LogisticRegression(n_features)\n",
    "\n",
    "    # record losses and accuracies report from clients\n",
    "    losses = [[] for i in range(n_hospitals)]\n",
    "    accuracies = [[] for i in range(n_hospitals)]\n",
    "    \n",
    "    pbar = tqdm(range(iterations), desc='Federated Learning Process')\n",
    "    for iteration in pbar:\n",
    "        if iteration:\n",
    "            # copy global model to clients\n",
    "            # clients will receive the weight-aggregated from server, extract\n",
    "            # the ciphertext then decrypt it to get to global_model's weights\n",
    "            for i in range(n_hospitals):\n",
    "                clients[i].decrypted_model_params()\n",
    "                print()\n",
    "        # perform local training for each clients then report acc and loss to server\n",
    "        for i in range(n_hospitals):\n",
    "            clients[i].local_training(debug=False)\n",
    "            \n",
    "            # report to server\n",
    "            losses[i].append(clients[i].losses[-1])\n",
    "            accuracies[i].append(clients[i].accuracies[-1])\n",
    "        \n",
    "        # clients encrypt the final weights of local model after training\n",
    "        for i in range(n_hospitals):\n",
    "            clients[i].encrypted_model_params()\n",
    "        \n",
    "        # server collect clients's encrypted weights then perform weight-aggregation\n",
    "        # by using homomorphic operation\n",
    "        with torch.no_grad():\n",
    "            # avg_weight = sum([clients[i].local_model.linear.weight.data for i in range(n_hospitals)]) / n_hospitals\n",
    "            # global_model.linear.weight = nn.Parameter(avg_weight)\n",
    "            # avg_bias = sum([clients[i].local_model.linear.bias.data for i in range(n_hospitals)]) / n_hospitals\n",
    "            # global_model.linear.bias = nn.Parameter(avg_bias)\n",
    "            aggregator()\n",
    "    \n",
    "        # logging\n",
    "        if (iteration + 1) % 100 == 0:\n",
    "            losses_str = ['{:.4f}'.format(losses[i][-1]) for i in range(n_hospitals)]\n",
    "            accuracies_str = [to_percent(accuracies[i][-1]) for i in range(n_hospitals)]\n",
    "            print('[LOG] Epoch = {0:04d}\\n> Losses = {1}\\n> Accuracies = {2}'.format(iteration + 1, losses_str, accuracies_str))\n",
    "        \n",
    "    return losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4cb88a05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a99020b635b4994ac077c48d931b9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Federated Learning Process:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0036727736587636173, 0.03148419409990311, -0.002163586934329942, 0.029379346407949924, 0.03130966890603304, 0.00885923660825938, 0.018477865494787693, 0.028796976432204247, 0.03204862400889397, 0.0039005823200568557, -0.0135551318526268, 0.03043943690136075, -0.009905524319037795, 0.0300748310983181, 0.03179200366139412, 0.012496640905737877, 0.013698277762159705, 0.01720318919979036, 0.024096897803246975, 0.006825356045737863, 0.0016553089080844074, 0.03374871797859669, 0.002907469926867634, 0.035148815251886845, 0.03225793410092592, 0.00977823045104742, 0.025984923355281353, 0.016312079271301627, 0.023383701220154762, 0.0171636373270303, 0.015710496809333563, -0.0001606017649464775]\n",
      "\n",
      "[0.0036727736587636173, 0.03148419409990311, -0.002163586934329942, 0.029379346407949924, 0.03130966890603304, 0.00885923660825938, 0.018477865494787693, 0.028796976432204247, 0.03204862400889397, 0.0039005823200568557, -0.0135551318526268, 0.03043943690136075, -0.009905524319037795, 0.0300748310983181, 0.03179200366139412, 0.012496640905737877, 0.013698277762159705, 0.01720318919979036, 0.024096897803246975, 0.006825356045737863, 0.0016553089080844074, 0.03374871797859669, 0.002907469926867634, 0.035148815251886845, 0.03225793410092592, 0.00977823045104742, 0.025984923355281353, 0.016312079271301627, 0.023383701220154762, 0.0171636373270303, 0.015710496809333563, -0.0001606017649464775]\n",
      "\n",
      "[0.0036727736587636173, 0.03148419409990311, -0.002163586934329942, 0.029379346407949924, 0.03130966890603304, 0.00885923660825938, 0.018477865494787693, 0.028796976432204247, 0.03204862400889397, 0.0039005823200568557, -0.0135551318526268, 0.03043943690136075, -0.009905524319037795, 0.0300748310983181, 0.03179200366139412, 0.012496640905737877, 0.013698277762159705, 0.01720318919979036, 0.024096897803246975, 0.006825356045737863, 0.0016553089080844074, 0.03374871797859669, 0.002907469926867634, 0.035148815251886845, 0.03225793410092592, 0.00977823045104742, 0.025984923355281353, 0.016312079271301627, 0.023383701220154762, 0.0171636373270303, 0.015710496809333563, -0.0001606017649464775]\n",
      "\n",
      "[0.0036727736587636173, 0.03148419409990311, -0.002163586934329942, 0.029379346407949924, 0.03130966890603304, 0.00885923660825938, 0.018477865494787693, 0.028796976432204247, 0.03204862400889397, 0.0039005823200568557, -0.0135551318526268, 0.03043943690136075, -0.009905524319037795, 0.0300748310983181, 0.03179200366139412, 0.012496640905737877, 0.013698277762159705, 0.01720318919979036, 0.024096897803246975, 0.006825356045737863, 0.0016553089080844074, 0.03374871797859669, 0.002907469926867634, 0.035148815251886845, 0.03225793410092592, 0.00977823045104742, 0.025984923355281353, 0.016312079271301627, 0.023383701220154762, 0.0171636373270303, 0.015710496809333563, -0.0001606017649464775]\n",
      "\n",
      "[0.011367178754881024, 0.11442441865801811, -0.00814197480212897, 0.10679714567959309, 0.1136102993041277, 0.03204099042341113, 0.06645536981523037, 0.10429865308105946, 0.1163160465657711, 0.01378134055994451, -0.05011917091906071, 0.11015125177800655, -0.03670696821063757, 0.1086472887545824, 0.11520701088011265, 0.04425871931016445, 0.04865988343954086, 0.061356387101113796, 0.086915772408247, 0.023913792800158262, 0.004802460636710748, 0.12280814349651337, 0.010623284615576267, 0.12799660861492157, 0.11724494025111198, 0.035142445005476475, 0.09405540488660336, 0.058527424931526184, 0.08509601838886738, 0.062468890100717545, 0.05639389529824257, -0.001125793918618001]\n",
      "\n",
      "[0.011367178754881024, 0.11442441865801811, -0.00814197480212897, 0.10679714567959309, 0.1136102993041277, 0.03204099042341113, 0.06645536981523037, 0.10429865308105946, 0.1163160465657711, 0.01378134055994451, -0.05011917091906071, 0.11015125177800655, -0.03670696821063757, 0.1086472887545824, 0.11520701088011265, 0.04425871931016445, 0.04865988343954086, 0.061356387101113796, 0.086915772408247, 0.023913792800158262, 0.004802460636710748, 0.12280814349651337, 0.010623284615576267, 0.12799660861492157, 0.11724494025111198, 0.035142445005476475, 0.09405540488660336, 0.058527424931526184, 0.08509601838886738, 0.062468890100717545, 0.05639389529824257, -0.001125793918618001]\n",
      "\n",
      "[0.011367178754881024, 0.11442441865801811, -0.00814197480212897, 0.10679714567959309, 0.1136102993041277, 0.03204099042341113, 0.06645536981523037, 0.10429865308105946, 0.1163160465657711, 0.01378134055994451, -0.05011917091906071, 0.11015125177800655, -0.03670696821063757, 0.1086472887545824, 0.11520701088011265, 0.04425871931016445, 0.04865988343954086, 0.061356387101113796, 0.086915772408247, 0.023913792800158262, 0.004802460636710748, 0.12280814349651337, 0.010623284615576267, 0.12799660861492157, 0.11724494025111198, 0.035142445005476475, 0.09405540488660336, 0.058527424931526184, 0.08509601838886738, 0.062468890100717545, 0.05639389529824257, -0.001125793918618001]\n",
      "\n",
      "[0.011367178754881024, 0.11442441865801811, -0.00814197480212897, 0.10679714567959309, 0.1136102993041277, 0.03204099042341113, 0.06645536981523037, 0.10429865308105946, 0.1163160465657711, 0.01378134055994451, -0.05011917091906071, 0.11015125177800655, -0.03670696821063757, 0.1086472887545824, 0.11520701088011265, 0.04425871931016445, 0.04865988343954086, 0.061356387101113796, 0.086915772408247, 0.023913792800158262, 0.004802460636710748, 0.12280814349651337, 0.010623284615576267, 0.12799660861492157, 0.11724494025111198, 0.035142445005476475, 0.09405540488660336, 0.058527424931526184, 0.08509601838886738, 0.062468890100717545, 0.05639389529824257, -0.001125793918618001]\n",
      "\n",
      "[0.030360122909769416, 0.38429686054587364, -0.02814119216054678, 0.3588382266461849, 0.3807563781738281, 0.10717041045427322, 0.22047114372253418, 0.34890745393931866, 0.39008862152695656, 0.044902269495651126, -0.1714224759489298, 0.3679538369178772, -0.12598936446011066, 0.36221449077129364, 0.3853651396930218, 0.14404240250587463, 0.15918479673564434, 0.20157869160175323, 0.28936978429555893, 0.07665440160781145, 0.01136480868444778, 0.41302555426955223, 0.036129303742200136, 0.4306700639426708, 0.3937864936888218, 0.11666887253522873, 0.31446101143956184, 0.1939512100070715, 0.28662933222949505, 0.21040229871869087, 0.18667586334049702, -0.004047554248245433]\n",
      "\n",
      "[0.030360122909769416, 0.38429686054587364, -0.02814119216054678, 0.3588382266461849, 0.3807563781738281, 0.10717041045427322, 0.22047114372253418, 0.34890745393931866, 0.39008862152695656, 0.044902269495651126, -0.1714224759489298, 0.3679538369178772, -0.12598936446011066, 0.36221449077129364, 0.3853651396930218, 0.14404240250587463, 0.15918479673564434, 0.20157869160175323, 0.28936978429555893, 0.07665440160781145, 0.01136480868444778, 0.41302555426955223, 0.036129303742200136, 0.4306700639426708, 0.3937864936888218, 0.11666887253522873, 0.31446101143956184, 0.1939512100070715, 0.28662933222949505, 0.21040229871869087, 0.18667586334049702, -0.004047554248245433]\n",
      "\n",
      "[0.030360122909769416, 0.38429686054587364, -0.02814119216054678, 0.3588382266461849, 0.3807563781738281, 0.10717041045427322, 0.22047114372253418, 0.34890745393931866, 0.39008862152695656, 0.044902269495651126, -0.1714224759489298, 0.3679538369178772, -0.12598936446011066, 0.36221449077129364, 0.3853651396930218, 0.14404240250587463, 0.15918479673564434, 0.20157869160175323, 0.28936978429555893, 0.07665440160781145, 0.01136480868444778, 0.41302555426955223, 0.036129303742200136, 0.4306700639426708, 0.3937864936888218, 0.11666887253522873, 0.31446101143956184, 0.1939512100070715, 0.28662933222949505, 0.21040229871869087, 0.18667586334049702, -0.004047554248245433]\n",
      "\n",
      "[0.030360122909769416, 0.38429686054587364, -0.02814119216054678, 0.3588382266461849, 0.3807563781738281, 0.10717041045427322, 0.22047114372253418, 0.34890745393931866, 0.39008862152695656, 0.044902269495651126, -0.1714224759489298, 0.3679538369178772, -0.12598936446011066, 0.36221449077129364, 0.3853651396930218, 0.14404240250587463, 0.15918479673564434, 0.20157869160175323, 0.28936978429555893, 0.07665440160781145, 0.01136480868444778, 0.41302555426955223, 0.036129303742200136, 0.4306700639426708, 0.3937864936888218, 0.11666887253522873, 0.31446101143956184, 0.1939512100070715, 0.28662933222949505, 0.21040229871869087, 0.18667586334049702, -0.004047554248245433]\n",
      "\n",
      "[0.10692993178963661, 1.5424607992172241, -0.11334176547825336, 1.4408034980297089, 1.5259935557842255, 0.4306950718164444, 0.8804287761449814, 1.3976825773715973, 1.5651623010635376, 0.1787005178630352, -0.694331482052803, 1.471939504146576, -0.5117050111293793, 1.4479573369026184, 1.5422108471393585, 0.5690597146749496, 0.6320115476846695, 0.8013386130332947, 1.1571609377861023, 0.29996807873249054, 0.03638024069368839, 1.6587416529655457, 0.1472538523375988, 1.7291660010814667, 1.5798453986644745, 0.4673007130622864, 1.2600283026695251, 0.7756404429674149, 1.1544403731822968, 0.8473746478557587, 0.7444890439510345, -0.007288468070328236]\n",
      "\n",
      "[0.10692993178963661, 1.5424607992172241, -0.11334176547825336, 1.4408034980297089, 1.5259935557842255, 0.4306950718164444, 0.8804287761449814, 1.3976825773715973, 1.5651623010635376, 0.1787005178630352, -0.694331482052803, 1.471939504146576, -0.5117050111293793, 1.4479573369026184, 1.5422108471393585, 0.5690597146749496, 0.6320115476846695, 0.8013386130332947, 1.1571609377861023, 0.29996807873249054, 0.03638024069368839, 1.6587416529655457, 0.1472538523375988, 1.7291660010814667, 1.5798453986644745, 0.4673007130622864, 1.2600283026695251, 0.7756404429674149, 1.1544403731822968, 0.8473746478557587, 0.7444890439510345, -0.007288468070328236]\n",
      "\n",
      "[0.10692993178963661, 1.5424607992172241, -0.11334176547825336, 1.4408034980297089, 1.5259935557842255, 0.4306950718164444, 0.8804287761449814, 1.3976825773715973, 1.5651623010635376, 0.1787005178630352, -0.694331482052803, 1.471939504146576, -0.5117050111293793, 1.4479573369026184, 1.5422108471393585, 0.5690597146749496, 0.6320115476846695, 0.8013386130332947, 1.1571609377861023, 0.29996807873249054, 0.03638024069368839, 1.6587416529655457, 0.1472538523375988, 1.7291660010814667, 1.5798453986644745, 0.4673007130622864, 1.2600283026695251, 0.7756404429674149, 1.1544403731822968, 0.8473746478557587, 0.7444890439510345, -0.007288468070328236]\n",
      "\n",
      "[0.10692993178963661, 1.5424607992172241, -0.11334176547825336, 1.4408034980297089, 1.5259935557842255, 0.4306950718164444, 0.8804287761449814, 1.3976825773715973, 1.5651623010635376, 0.1787005178630352, -0.694331482052803, 1.471939504146576, -0.5117050111293793, 1.4479573369026184, 1.5422108471393585, 0.5690597146749496, 0.6320115476846695, 0.8013386130332947, 1.1571609377861023, 0.29996807873249054, 0.03638024069368839, 1.6587416529655457, 0.1472538523375988, 1.7291660010814667, 1.5798453986644745, 0.4673007130622864, 1.2600283026695251, 0.7756404429674149, 1.1544403731822968, 0.8473746478557587, 0.7444890439510345, -0.007288468070328236]\n",
      "\n",
      "[0.5172617174685001, 7.711061090230942, -0.5671885889023542, 7.2036005556583405, 7.626255005598068, 2.1541719138622284, 4.397179335355759, 6.984171569347382, 7.824356853961945, 0.8924073912203312, -3.4796643257141113, 7.3525503277778625, -2.5669611990451813, 7.231817692518234, 7.704131603240967, 2.8345179557800293, 3.151796832680702, 3.9968080073595047, 5.780506283044815, 1.4907631278038025, 0.1707518147304654, 8.293578624725342, 0.7388584688305855, 8.644962757825851, 7.896749526262283, 2.336229830980301, 6.297241747379303, 3.8754231482744217, 5.777058899402618, 4.2412130534648895, 3.716491535305977, -0.023857015185058117]\n",
      "\n",
      "[0.5172617174685001, 7.711061090230942, -0.5671885889023542, 7.2036005556583405, 7.626255005598068, 2.1541719138622284, 4.397179335355759, 6.984171569347382, 7.824356853961945, 0.8924073912203312, -3.4796643257141113, 7.3525503277778625, -2.5669611990451813, 7.231817692518234, 7.704131603240967, 2.8345179557800293, 3.151796832680702, 3.9968080073595047, 5.780506283044815, 1.4907631278038025, 0.1707518147304654, 8.293578624725342, 0.7388584688305855, 8.644962757825851, 7.896749526262283, 2.336229830980301, 6.297241747379303, 3.8754231482744217, 5.777058899402618, 4.2412130534648895, 3.716491535305977, -0.023857015185058117]\n",
      "\n",
      "[0.5172617174685001, 7.711061090230942, -0.5671885889023542, 7.2036005556583405, 7.626255005598068, 2.1541719138622284, 4.397179335355759, 6.984171569347382, 7.824356853961945, 0.8924073912203312, -3.4796643257141113, 7.3525503277778625, -2.5669611990451813, 7.231817692518234, 7.704131603240967, 2.8345179557800293, 3.151796832680702, 3.9968080073595047, 5.780506283044815, 1.4907631278038025, 0.1707518147304654, 8.293578624725342, 0.7388584688305855, 8.644962757825851, 7.896749526262283, 2.336229830980301, 6.297241747379303, 3.8754231482744217, 5.777058899402618, 4.2412130534648895, 3.716491535305977, -0.023857015185058117]\n",
      "\n",
      "[0.5172617174685001, 7.711061090230942, -0.5671885889023542, 7.2036005556583405, 7.626255005598068, 2.1541719138622284, 4.397179335355759, 6.984171569347382, 7.824356853961945, 0.8924073912203312, -3.4796643257141113, 7.3525503277778625, -2.5669611990451813, 7.231817692518234, 7.704131603240967, 2.8345179557800293, 3.151796832680702, 3.9968080073595047, 5.780506283044815, 1.4907631278038025, 0.1707518147304654, 8.293578624725342, 0.7388584688305855, 8.644962757825851, 7.896749526262283, 2.336229830980301, 6.297241747379303, 3.8754231482744217, 5.777058899402618, 4.2412130534648895, 3.716491535305977, -0.023857015185058117]\n",
      "\n",
      "[3.0947906970977783, 46.26573300361633, -3.4041946828365326, 43.2213020324707, 45.75569200515747, 12.92738127708435, 26.382482528686523, 41.90429162979126, 46.94711494445801, 5.355145275592804, -20.880228281021118, 44.11241912841797, -15.40561580657959, 43.38673639297485, 46.22161388397217, 17.003057599067688, 18.90888547897339, 23.977779865264893, 34.68125867843628, 8.941204190254211, 1.020725928246975, 49.76208972930908, 4.43351948261261, 51.86928749084473, 47.37935972213745, 14.018949151039124, 37.783814907073975, 23.253222227096558, 34.666542291641235, 25.451053619384766, 22.29822850227356, -0.13610847294330597]\n",
      "\n",
      "[3.0947906970977783, 46.26573300361633, -3.4041946828365326, 43.2213020324707, 45.75569200515747, 12.92738127708435, 26.382482528686523, 41.90429162979126, 46.94711494445801, 5.355145275592804, -20.880228281021118, 44.11241912841797, -15.40561580657959, 43.38673639297485, 46.22161388397217, 17.003057599067688, 18.90888547897339, 23.977779865264893, 34.68125867843628, 8.941204190254211, 1.020725928246975, 49.76208972930908, 4.43351948261261, 51.86928749084473, 47.37935972213745, 14.018949151039124, 37.783814907073975, 23.253222227096558, 34.666542291641235, 25.451053619384766, 22.29822850227356, -0.13610847294330597]\n",
      "\n",
      "[3.0947906970977783, 46.26573300361633, -3.4041946828365326, 43.2213020324707, 45.75569200515747, 12.92738127708435, 26.382482528686523, 41.90429162979126, 46.94711494445801, 5.355145275592804, -20.880228281021118, 44.11241912841797, -15.40561580657959, 43.38673639297485, 46.22161388397217, 17.003057599067688, 18.90888547897339, 23.977779865264893, 34.68125867843628, 8.941204190254211, 1.020725928246975, 49.76208972930908, 4.43351948261261, 51.86928749084473, 47.37935972213745, 14.018949151039124, 37.783814907073975, 23.253222227096558, 34.666542291641235, 25.451053619384766, 22.29822850227356, -0.13610847294330597]\n",
      "\n",
      "[3.0947906970977783, 46.26573300361633, -3.4041946828365326, 43.2213020324707, 45.75569200515747, 12.92738127708435, 26.382482528686523, 41.90429162979126, 46.94711494445801, 5.355145275592804, -20.880228281021118, 44.11241912841797, -15.40561580657959, 43.38673639297485, 46.22161388397217, 17.003057599067688, 18.90888547897339, 23.977779865264893, 34.68125867843628, 8.941204190254211, 1.020725928246975, 49.76208972930908, 4.43351948261261, 51.86928749084473, 47.37935972213745, 14.018949151039124, 37.783814907073975, 23.253222227096558, 34.666542291641235, 25.451053619384766, 22.29822850227356, -0.13610847294330597]\n",
      "\n",
      "[21.661724090576172, 323.8603229522705, -23.829779386520386, 302.5488471984863, 320.2897071838379, 90.49061918258667, 184.67677688598633, 293.3290500640869, 328.6300582885742, 37.48532557487488, -146.1629981994629, 308.7870674133301, -107.84031200408936, 303.7054958343506, 323.5510368347168, 119.02160263061523, 132.3622350692749, 167.84422206878662, 242.7676124572754, 62.58752727508545, 7.143888473510742, 348.3357563018799, 31.03360915184021, 363.08459854125977, 331.65552139282227, 98.13242959976196, 264.48716163635254, 162.77335166931152, 242.66639518737793, 178.15841007232666, 156.08867263793945, -0.9498991817235947]\n",
      "\n",
      "[21.661724090576172, 323.8603229522705, -23.829779386520386, 302.5488471984863, 320.2897071838379, 90.49061918258667, 184.67677688598633, 293.3290500640869, 328.6300582885742, 37.48532557487488, -146.1629981994629, 308.7870674133301, -107.84031200408936, 303.7054958343506, 323.5510368347168, 119.02160263061523, 132.3622350692749, 167.84422206878662, 242.7676124572754, 62.58752727508545, 7.143888473510742, 348.3357563018799, 31.03360915184021, 363.08459854125977, 331.65552139282227, 98.13242959976196, 264.48716163635254, 162.77335166931152, 242.66639518737793, 178.15841007232666, 156.08867263793945, -0.9498991817235947]\n",
      "\n",
      "[21.661724090576172, 323.8603229522705, -23.829779386520386, 302.5488471984863, 320.2897071838379, 90.49061918258667, 184.67677688598633, 293.3290500640869, 328.6300582885742, 37.48532557487488, -146.1629981994629, 308.7870674133301, -107.84031200408936, 303.7054958343506, 323.5510368347168, 119.02160263061523, 132.3622350692749, 167.84422206878662, 242.7676124572754, 62.58752727508545, 7.143888473510742, 348.3357563018799, 31.03360915184021, 363.08459854125977, 331.65552139282227, 98.13242959976196, 264.48716163635254, 162.77335166931152, 242.66639518737793, 178.15841007232666, 156.08867263793945, -0.9498991817235947]\n",
      "\n",
      "[21.661724090576172, 323.8603229522705, -23.829779386520386, 302.5488471984863, 320.2897071838379, 90.49061918258667, 184.67677688598633, 293.3290500640869, 328.6300582885742, 37.48532557487488, -146.1629981994629, 308.7870674133301, -107.84031200408936, 303.7054958343506, 323.5510368347168, 119.02160263061523, 132.3622350692749, 167.84422206878662, 242.7676124572754, 62.58752727508545, 7.143888473510742, 348.3357563018799, 31.03360915184021, 363.08459854125977, 331.65552139282227, 98.13242959976196, 264.48716163635254, 162.77335166931152, 242.66639518737793, 178.15841007232666, 156.08867263793945, -0.9498991817235947]\n",
      "\n",
      "[173.29348754882812, 2590.882568359375, -190.63826751708984, 2420.390869140625, 2562.317626953125, 723.9249267578125, 1477.4141845703125, 2346.63232421875, 2629.04052734375, 299.8825225830078, -1169.303955078125, 2470.296630859375, -862.7226257324219, 2429.64404296875, 2588.408203125, 952.1726989746094, 1058.8978271484375, 1342.7537841796875, 1942.140869140625, 500.7000732421875, 57.15100288391113, 2786.68603515625, 248.26891326904297, 2904.6767578125, 2653.244140625, 785.0594482421875, 2115.897216796875, 1302.186767578125, 1941.3314819335938, 1425.267333984375, 1248.7093505859375, -7.5989909172058105]\n",
      "\n",
      "[173.29348754882812, 2590.882568359375, -190.63826751708984, 2420.390869140625, 2562.317626953125, 723.9249267578125, 1477.4141845703125, 2346.63232421875, 2629.04052734375, 299.8825225830078, -1169.303955078125, 2470.296630859375, -862.7226257324219, 2429.64404296875, 2588.408203125, 952.1726989746094, 1058.8978271484375, 1342.7537841796875, 1942.140869140625, 500.7000732421875, 57.15100288391113, 2786.68603515625, 248.26891326904297, 2904.6767578125, 2653.244140625, 785.0594482421875, 2115.897216796875, 1302.186767578125, 1941.3314819335938, 1425.267333984375, 1248.7093505859375, -7.5989909172058105]\n",
      "\n",
      "[173.29348754882812, 2590.882568359375, -190.63826751708984, 2420.390869140625, 2562.317626953125, 723.9249267578125, 1477.4141845703125, 2346.63232421875, 2629.04052734375, 299.8825225830078, -1169.303955078125, 2470.296630859375, -862.7226257324219, 2429.64404296875, 2588.408203125, 952.1726989746094, 1058.8978271484375, 1342.7537841796875, 1942.140869140625, 500.7000732421875, 57.15100288391113, 2786.68603515625, 248.26891326904297, 2904.6767578125, 2653.244140625, 785.0594482421875, 2115.897216796875, 1302.186767578125, 1941.3314819335938, 1425.267333984375, 1248.7093505859375, -7.5989909172058105]\n",
      "\n",
      "[173.29348754882812, 2590.882568359375, -190.63826751708984, 2420.390869140625, 2562.317626953125, 723.9249267578125, 1477.4141845703125, 2346.63232421875, 2629.04052734375, 299.8825225830078, -1169.303955078125, 2470.296630859375, -862.7226257324219, 2429.64404296875, 2588.408203125, 952.1726989746094, 1058.8978271484375, 1342.7537841796875, 1942.140869140625, 500.7000732421875, 57.15100288391113, 2786.68603515625, 248.26891326904297, 2904.6767578125, 2653.244140625, 785.0594482421875, 2115.897216796875, 1302.186767578125, 1941.3314819335938, 1425.267333984375, 1248.7093505859375, -7.5989909172058105]\n",
      "\n",
      "[1559.6413879394531, 23317.943115234375, -1715.7444763183594, 21783.517822265625, 23060.858642578125, 6515.3243408203125, 13296.727661132812, 21119.69091796875, 23661.36474609375, 2698.9425659179688, -10523.735595703125, 22232.669677734375, -7764.50390625, 21866.79638671875, 23295.673828125, 8569.554565429688, 9530.080444335938, 12084.784057617188, 17479.267822265625, 4506.3006591796875, 514.3590087890625, 25080.17431640625, 2234.4202880859375, 26142.0908203125, 23879.197265625, 7065.5350341796875, 19043.074951171875, 11719.680908203125, 17471.98388671875, 12827.406005859375, 11238.384155273438, -68.3909182548523]\n",
      "\n",
      "[1559.6413879394531, 23317.943115234375, -1715.7444763183594, 21783.517822265625, 23060.858642578125, 6515.3243408203125, 13296.727661132812, 21119.69091796875, 23661.36474609375, 2698.9425659179688, -10523.735595703125, 22232.669677734375, -7764.50390625, 21866.79638671875, 23295.673828125, 8569.554565429688, 9530.080444335938, 12084.784057617188, 17479.267822265625, 4506.3006591796875, 514.3590087890625, 25080.17431640625, 2234.4202880859375, 26142.0908203125, 23879.197265625, 7065.5350341796875, 19043.074951171875, 11719.680908203125, 17471.98388671875, 12827.406005859375, 11238.384155273438, -68.3909182548523]\n",
      "\n",
      "[1559.6413879394531, 23317.943115234375, -1715.7444763183594, 21783.517822265625, 23060.858642578125, 6515.3243408203125, 13296.727661132812, 21119.69091796875, 23661.36474609375, 2698.9425659179688, -10523.735595703125, 22232.669677734375, -7764.50390625, 21866.79638671875, 23295.673828125, 8569.554565429688, 9530.080444335938, 12084.784057617188, 17479.267822265625, 4506.3006591796875, 514.3590087890625, 25080.17431640625, 2234.4202880859375, 26142.0908203125, 23879.197265625, 7065.5350341796875, 19043.074951171875, 11719.680908203125, 17471.98388671875, 12827.406005859375, 11238.384155273438, -68.3909182548523]\n",
      "\n",
      "[1559.6413879394531, 23317.943115234375, -1715.7444763183594, 21783.517822265625, 23060.858642578125, 6515.3243408203125, 13296.727661132812, 21119.69091796875, 23661.36474609375, 2698.9425659179688, -10523.735595703125, 22232.669677734375, -7764.50390625, 21866.79638671875, 23295.673828125, 8569.554565429688, 9530.080444335938, 12084.784057617188, 17479.267822265625, 4506.3006591796875, 514.3590087890625, 25080.17431640625, 2234.4202880859375, 26142.0908203125, 23879.197265625, 7065.5350341796875, 19043.074951171875, 11719.680908203125, 17471.98388671875, 12827.406005859375, 11238.384155273438, -68.3909182548523]\n",
      "\n",
      "[15596.41357421875, 233179.43359375, -17157.445068359375, 217835.17578125, 230608.59375, 65153.2421875, 132967.275390625, 211196.9140625, 236613.65234375, 26989.42626953125, -105237.353515625, 222326.69921875, -77645.0390625, 218667.96875, 232956.73828125, 85695.546875, 95300.80078125, 120847.841796875, 174792.67578125, 45063.0078125, 5143.590087890625, 250801.73828125, 22344.2041015625, 261420.8984375, 238791.97265625, 70655.3515625, 190430.7421875, 117196.806640625, 174719.84375, 128274.0625, 112383.837890625, -683.9091491699219]\n",
      "\n",
      "[15596.41357421875, 233179.43359375, -17157.445068359375, 217835.17578125, 230608.59375, 65153.2421875, 132967.275390625, 211196.9140625, 236613.65234375, 26989.42626953125, -105237.353515625, 222326.69921875, -77645.0390625, 218667.96875, 232956.73828125, 85695.546875, 95300.80078125, 120847.841796875, 174792.67578125, 45063.0078125, 5143.590087890625, 250801.73828125, 22344.2041015625, 261420.8984375, 238791.97265625, 70655.3515625, 190430.7421875, 117196.806640625, 174719.84375, 128274.0625, 112383.837890625, -683.9091491699219]\n",
      "\n",
      "[15596.41357421875, 233179.43359375, -17157.445068359375, 217835.17578125, 230608.59375, 65153.2421875, 132967.275390625, 211196.9140625, 236613.65234375, 26989.42626953125, -105237.353515625, 222326.69921875, -77645.0390625, 218667.96875, 232956.73828125, 85695.546875, 95300.80078125, 120847.841796875, 174792.67578125, 45063.0078125, 5143.590087890625, 250801.73828125, 22344.2041015625, 261420.8984375, 238791.97265625, 70655.3515625, 190430.7421875, 117196.806640625, 174719.84375, 128274.0625, 112383.837890625, -683.9091491699219]\n",
      "\n",
      "[15596.41357421875, 233179.43359375, -17157.445068359375, 217835.17578125, 230608.59375, 65153.2421875, 132967.275390625, 211196.9140625, 236613.65234375, 26989.42626953125, -105237.353515625, 222326.69921875, -77645.0390625, 218667.96875, 232956.73828125, 85695.546875, 95300.80078125, 120847.841796875, 174792.67578125, 45063.0078125, 5143.590087890625, 250801.73828125, 22344.2041015625, 261420.8984375, 238791.97265625, 70655.3515625, 190430.7421875, 117196.806640625, 174719.84375, 128274.0625, 112383.837890625, -683.9091491699219]\n",
      "\n",
      "[171560.5546875, 2564973.8125, -188731.8984375, 2396186.890625, 2536694.53125, 716685.6640625, 1462640.09375, 2323165.96875, 2602750.21875, 296883.68359375, -1157610.8671875, 2445593.734375, -854095.4296875, 2405347.65625, 2562524.078125, 942651.015625, 1048308.765625, 1329326.28125, 1922719.390625, 495693.0859375, 56579.48828125, 2758819.078125, 245786.234375, 2875629.96875, 2626711.65625, 777208.8671875, 2094738.25, 1289164.8515625, 1921918.28125, 1411014.6875, 1236222.1953125, -7523.0009765625]\n",
      "\n",
      "[171560.5546875, 2564973.8125, -188731.8984375, 2396186.890625, 2536694.53125, 716685.6640625, 1462640.09375, 2323165.96875, 2602750.21875, 296883.68359375, -1157610.8671875, 2445593.734375, -854095.4296875, 2405347.65625, 2562524.078125, 942651.015625, 1048308.765625, 1329326.28125, 1922719.390625, 495693.0859375, 56579.48828125, 2758819.078125, 245786.234375, 2875629.96875, 2626711.65625, 777208.8671875, 2094738.25, 1289164.8515625, 1921918.28125, 1411014.6875, 1236222.1953125, -7523.0009765625]\n",
      "\n",
      "[171560.5546875, 2564973.8125, -188731.8984375, 2396186.890625, 2536694.53125, 716685.6640625, 1462640.09375, 2323165.96875, 2602750.21875, 296883.68359375, -1157610.8671875, 2445593.734375, -854095.4296875, 2405347.65625, 2562524.078125, 942651.015625, 1048308.765625, 1329326.28125, 1922719.390625, 495693.0859375, 56579.48828125, 2758819.078125, 245786.234375, 2875629.96875, 2626711.65625, 777208.8671875, 2094738.25, 1289164.8515625, 1921918.28125, 1411014.6875, 1236222.1953125, -7523.0009765625]\n",
      "\n",
      "[171560.5546875, 2564973.8125, -188731.8984375, 2396186.890625, 2536694.53125, 716685.6640625, 1462640.09375, 2323165.96875, 2602750.21875, 296883.68359375, -1157610.8671875, 2445593.734375, -854095.4296875, 2405347.65625, 2562524.078125, 942651.015625, 1048308.765625, 1329326.28125, 1922719.390625, 495693.0859375, 56579.48828125, 2758819.078125, 245786.234375, 2875629.96875, 2626711.65625, 777208.8671875, 2094738.25, 1289164.8515625, 1921918.28125, 1411014.6875, 1236222.1953125, -7523.0009765625]\n",
      "\n",
      "[2058726.75, 30779685.0, -2264782.875, 28754244.0, 30440334.0, 8600228.25, 17551681.5, 27877992.0, 31233003.0, 3562604.25, -13891330.5, 29347125.0, -10249145.25, 28864173.0, 30750288.0, 11311812.0, 12579705.0, 15951915.0, 23072632.5, 5948317.125, 678953.859375, 33105828.0, 2949434.8125, 34507560.0, 31520541.0, 9326506.5, 25136859.0, 15469978.5, 23063019.0, 16932177.0, 14834667.0, -90276.01171875]\n",
      "\n",
      "[2058726.75, 30779685.0, -2264782.875, 28754244.0, 30440334.0, 8600228.25, 17551681.5, 27877992.0, 31233003.0, 3562604.25, -13891330.5, 29347125.0, -10249145.25, 28864173.0, 30750288.0, 11311812.0, 12579705.0, 15951915.0, 23072632.5, 5948317.125, 678953.859375, 33105828.0, 2949434.8125, 34507560.0, 31520541.0, 9326506.5, 25136859.0, 15469978.5, 23063019.0, 16932177.0, 14834667.0, -90276.01171875]\n",
      "\n",
      "[2058726.75, 30779685.0, -2264782.875, 28754244.0, 30440334.0, 8600228.25, 17551681.5, 27877992.0, 31233003.0, 3562604.25, -13891330.5, 29347125.0, -10249145.25, 28864173.0, 30750288.0, 11311812.0, 12579705.0, 15951915.0, 23072632.5, 5948317.125, 678953.859375, 33105828.0, 2949434.8125, 34507560.0, 31520541.0, 9326506.5, 25136859.0, 15469978.5, 23063019.0, 16932177.0, 14834667.0, -90276.01171875]\n",
      "\n",
      "[2058726.75, 30779685.0, -2264782.875, 28754244.0, 30440334.0, 8600228.25, 17551681.5, 27877992.0, 31233003.0, 3562604.25, -13891330.5, 29347125.0, -10249145.25, 28864173.0, 30750288.0, 11311812.0, 12579705.0, 15951915.0, 23072632.5, 5948317.125, 678953.859375, 33105828.0, 2949434.8125, 34507560.0, 31520541.0, 9326506.5, 25136859.0, 15469978.5, 23063019.0, 16932177.0, 14834667.0, -90276.01171875]\n",
      "\n",
      "[26763447.75, 400135892.0, -29442179.0, 373805172.0, 395724342.0, 111802964.0, 228171866.0, 362413896.0, 406029052.0, 46313855.25, -180587290.0, 381512612.0, -133238885.0, 375234236.0, 399753744.0, 147053556.0, 163536165.0, 207374895.0, 299944216.0, 77328121.0, 8826400.375, 430375764.0, 38342651.75, 448598280.0, 409767020.0, 121244578.0, 326779180.0, 201109714.0, 299819260.0, 220118288.0, 192850671.0, -1173588.203125]\n",
      "\n",
      "[26763447.75, 400135892.0, -29442179.0, 373805172.0, 395724342.0, 111802964.0, 228171866.0, 362413896.0, 406029052.0, 46313855.25, -180587290.0, 381512612.0, -133238885.0, 375234236.0, 399753744.0, 147053556.0, 163536165.0, 207374895.0, 299944216.0, 77328121.0, 8826400.375, 430375764.0, 38342651.75, 448598280.0, 409767020.0, 121244578.0, 326779180.0, 201109714.0, 299819260.0, 220118288.0, 192850671.0, -1173588.203125]\n",
      "\n",
      "[26763447.75, 400135892.0, -29442179.0, 373805172.0, 395724342.0, 111802964.0, 228171866.0, 362413896.0, 406029052.0, 46313855.25, -180587290.0, 381512612.0, -133238885.0, 375234236.0, 399753744.0, 147053556.0, 163536165.0, 207374895.0, 299944216.0, 77328121.0, 8826400.375, 430375764.0, 38342651.75, 448598280.0, 409767020.0, 121244578.0, 326779180.0, 201109714.0, 299819260.0, 220118288.0, 192850671.0, -1173588.203125]\n",
      "\n",
      "[26763447.75, 400135892.0, -29442179.0, 373805172.0, 395724342.0, 111802964.0, 228171866.0, 362413896.0, 406029052.0, 46313855.25, -180587290.0, 381512612.0, -133238885.0, 375234236.0, 399753744.0, 147053556.0, 163536165.0, 207374895.0, 299944216.0, 77328121.0, 8826400.375, 430375764.0, 38342651.75, 448598280.0, 409767020.0, 121244578.0, 326779180.0, 201109714.0, 299819260.0, 220118288.0, 192850671.0, -1173588.203125]\n",
      "\n",
      "[374688272.0, 5601902656.0, -412190520.0, 5233272576.0, 5540140928.0, 1565241440.0, 3194406208.0, 5073794432.0, 5684406784.0, 648393984.0, -2528222144.0, 5341176512.0, -1865344432.0, 5253279360.0, 5596552192.0, 2058749728.0, 2289506240.0, 2903248544.0, 4199219136.0, 1082593680.0, 123569600.0, 6025260864.0, 536797128.0, 6280375808.0, 5736738112.0, 1697424064.0, 4574908352.0, 2815535968.0, 4197469696.0, 3081656032.0, 2699909408.0, -16430235.5]\n",
      "\n",
      "[374688272.0, 5601902656.0, -412190520.0, 5233272576.0, 5540140928.0, 1565241440.0, 3194406208.0, 5073794432.0, 5684406784.0, 648393984.0, -2528222144.0, 5341176512.0, -1865344432.0, 5253279360.0, 5596552192.0, 2058749728.0, 2289506240.0, 2903248544.0, 4199219136.0, 1082593680.0, 123569600.0, 6025260864.0, 536797128.0, 6280375808.0, 5736738112.0, 1697424064.0, 4574908352.0, 2815535968.0, 4197469696.0, 3081656032.0, 2699909408.0, -16430235.5]\n",
      "\n",
      "[374688272.0, 5601902656.0, -412190520.0, 5233272576.0, 5540140928.0, 1565241440.0, 3194406208.0, 5073794432.0, 5684406784.0, 648393984.0, -2528222144.0, 5341176512.0, -1865344432.0, 5253279360.0, 5596552192.0, 2058749728.0, 2289506240.0, 2903248544.0, 4199219136.0, 1082593680.0, 123569600.0, 6025260864.0, 536797128.0, 6280375808.0, 5736738112.0, 1697424064.0, 4574908352.0, 2815535968.0, 4197469696.0, 3081656032.0, 2699909408.0, -16430235.5]\n",
      "\n",
      "[374688272.0, 5601902656.0, -412190520.0, 5233272576.0, 5540140928.0, 1565241440.0, 3194406208.0, 5073794432.0, 5684406784.0, 648393984.0, -2528222144.0, 5341176512.0, -1865344432.0, 5253279360.0, 5596552192.0, 2058749728.0, 2289506240.0, 2903248544.0, 4199219136.0, 1082593680.0, 123569600.0, 6025260864.0, 536797128.0, 6280375808.0, 5736738112.0, 1697424064.0, 4574908352.0, 2815535968.0, 4197469696.0, 3081656032.0, 2699909408.0, -16430235.5]\n",
      "\n",
      "[5620323840.0, 84028538880.0, -6182857920.0, 78499092480.0, 83102115840.0, 23478622080.0, 47916092160.0, 76106918400.0, 85266101760.0, 9725909760.0, -37923333120.0, 80117644800.0, -27980165760.0, 78799188480.0, 83948282880.0, 30881245440.0, 34342594560.0, 43548729600.0, 62988288000.0, 16238904960.0, 1853544000.0, 90378915840.0, 8051956800.0, 94205637120.0, 86051074560.0, 25461361920.0, 68623626240.0, 42233038080.0, 62962045440.0, 46224840960.0, 40498640640.0, -246453540.0]\n",
      "\n",
      "[5620323840.0, 84028538880.0, -6182857920.0, 78499092480.0, 83102115840.0, 23478622080.0, 47916092160.0, 76106918400.0, 85266101760.0, 9725909760.0, -37923333120.0, 80117644800.0, -27980165760.0, 78799188480.0, 83948282880.0, 30881245440.0, 34342594560.0, 43548729600.0, 62988288000.0, 16238904960.0, 1853544000.0, 90378915840.0, 8051956800.0, 94205637120.0, 86051074560.0, 25461361920.0, 68623626240.0, 42233038080.0, 62962045440.0, 46224840960.0, 40498640640.0, -246453540.0]\n",
      "\n",
      "[5620323840.0, 84028538880.0, -6182857920.0, 78499092480.0, 83102115840.0, 23478622080.0, 47916092160.0, 76106918400.0, 85266101760.0, 9725909760.0, -37923333120.0, 80117644800.0, -27980165760.0, 78799188480.0, 83948282880.0, 30881245440.0, 34342594560.0, 43548729600.0, 62988288000.0, 16238904960.0, 1853544000.0, 90378915840.0, 8051956800.0, 94205637120.0, 86051074560.0, 25461361920.0, 68623626240.0, 42233038080.0, 62962045440.0, 46224840960.0, 40498640640.0, -246453540.0]\n",
      "\n",
      "[5620323840.0, 84028538880.0, -6182857920.0, 78499092480.0, 83102115840.0, 23478622080.0, 47916092160.0, 76106918400.0, 85266101760.0, 9725909760.0, -37923333120.0, 80117644800.0, -27980165760.0, 78799188480.0, 83948282880.0, 30881245440.0, 34342594560.0, 43548729600.0, 62988288000.0, 16238904960.0, 1853544000.0, 90378915840.0, 8051956800.0, 94205637120.0, 86051074560.0, 25461361920.0, 68623626240.0, 42233038080.0, 62962045440.0, 46224840960.0, 40498640640.0, -246453540.0]\n",
      "\n",
      "[89925181440.0, 1344456622080.0, -98925723648.0, 1255985512448.0, 1329633820672.0, 375657955328.0, 766657495040.0, 1217710653440.0, 1364257669120.0, 155614560256.0, -606773313536.0, 1281882324992.0, -447682641920.0, 1260787073024.0, 1343172509696.0, 494099922944.0, 549481512960.0, 696779669504.0, 1007812608000.0, 259822485504.0, 29656702976.0, 1446062587904.0, 128831307776.0, 1507290251264.0, 1376817250304.0, 407381803008.0, 1097978019840.0, 675728588800.0, 1007392718848.0, 739597484032.0, 647978221568.0, -3943256576.0]\n",
      "\n",
      "[89925181440.0, 1344456622080.0, -98925723648.0, 1255985512448.0, 1329633820672.0, 375657955328.0, 766657495040.0, 1217710653440.0, 1364257669120.0, 155614560256.0, -606773313536.0, 1281882324992.0, -447682641920.0, 1260787073024.0, 1343172509696.0, 494099922944.0, 549481512960.0, 696779669504.0, 1007812608000.0, 259822485504.0, 29656702976.0, 1446062587904.0, 128831307776.0, 1507290251264.0, 1376817250304.0, 407381803008.0, 1097978019840.0, 675728588800.0, 1007392718848.0, 739597484032.0, 647978221568.0, -3943256576.0]\n",
      "\n",
      "[89925181440.0, 1344456622080.0, -98925723648.0, 1255985512448.0, 1329633820672.0, 375657955328.0, 766657495040.0, 1217710653440.0, 1364257669120.0, 155614560256.0, -606773313536.0, 1281882324992.0, -447682641920.0, 1260787073024.0, 1343172509696.0, 494099922944.0, 549481512960.0, 696779669504.0, 1007812608000.0, 259822485504.0, 29656702976.0, 1446062587904.0, 128831307776.0, 1507290251264.0, 1376817250304.0, 407381803008.0, 1097978019840.0, 675728588800.0, 1007392718848.0, 739597484032.0, 647978221568.0, -3943256576.0]\n",
      "\n",
      "[89925181440.0, 1344456622080.0, -98925723648.0, 1255985512448.0, 1329633820672.0, 375657955328.0, 766657495040.0, 1217710653440.0, 1364257669120.0, 155614560256.0, -606773313536.0, 1281882324992.0, -447682641920.0, 1260787073024.0, 1343172509696.0, 494099922944.0, 549481512960.0, 696779669504.0, 1007812608000.0, 259822485504.0, 29656702976.0, 1446062587904.0, 128831307776.0, 1507290251264.0, 1376817250304.0, 407381803008.0, 1097978019840.0, 675728588800.0, 1007392718848.0, 739597484032.0, 647978221568.0, -3943256576.0]\n",
      "\n",
      "[1528728084480.0, 22855762575360.0, -1681737302016.0, 21351753711616.0, 22603774951424.0, 6386185240576.0, 13033177415680.0, 20701081108480.0, 23192380375040.0, 2645447524352.0, -10315146330112.0, 21791999524864.0, -7610604912640.0, 21433380241408.0, 22833932664832.0, 8399698690048.0, 9341185720320.0, 11845254381568.0, 17132814336000.0, 4416982253568.0, 504163950592.0, 24583063994368.0, 2190132232192.0, 25623934271488.0, 23405893255168.0, 6925490651136.0, 18665626337280.0, 11487386009600.0, 17125676220416.0, 12573157228544.0, 11015629766656.0, -67035361792.0]\n",
      "\n",
      "[1528728084480.0, 22855762575360.0, -1681737302016.0, 21351753711616.0, 22603774951424.0, 6386185240576.0, 13033177415680.0, 20701081108480.0, 23192380375040.0, 2645447524352.0, -10315146330112.0, 21791999524864.0, -7610604912640.0, 21433380241408.0, 22833932664832.0, 8399698690048.0, 9341185720320.0, 11845254381568.0, 17132814336000.0, 4416982253568.0, 504163950592.0, 24583063994368.0, 2190132232192.0, 25623934271488.0, 23405893255168.0, 6925490651136.0, 18665626337280.0, 11487386009600.0, 17125676220416.0, 12573157228544.0, 11015629766656.0, -67035361792.0]\n",
      "\n",
      "[1528728084480.0, 22855762575360.0, -1681737302016.0, 21351753711616.0, 22603774951424.0, 6386185240576.0, 13033177415680.0, 20701081108480.0, 23192380375040.0, 2645447524352.0, -10315146330112.0, 21791999524864.0, -7610604912640.0, 21433380241408.0, 22833932664832.0, 8399698690048.0, 9341185720320.0, 11845254381568.0, 17132814336000.0, 4416982253568.0, 504163950592.0, 24583063994368.0, 2190132232192.0, 25623934271488.0, 23405893255168.0, 6925490651136.0, 18665626337280.0, 11487386009600.0, 17125676220416.0, 12573157228544.0, 11015629766656.0, -67035361792.0]\n",
      "\n",
      "[1528728084480.0, 22855762575360.0, -1681737302016.0, 21351753711616.0, 22603774951424.0, 6386185240576.0, 13033177415680.0, 20701081108480.0, 23192380375040.0, 2645447524352.0, -10315146330112.0, 21791999524864.0, -7610604912640.0, 21433380241408.0, 22833932664832.0, 8399698690048.0, 9341185720320.0, 11845254381568.0, 17132814336000.0, 4416982253568.0, 504163950592.0, 24583063994368.0, 2190132232192.0, 25623934271488.0, 23405893255168.0, 6925490651136.0, 18665626337280.0, 11487386009600.0, 17125676220416.0, 12573157228544.0, 11015629766656.0, -67035361792.0]\n",
      "\n",
      "[27517106257920.0, 411403731075072.0, -30271270551552.0, 384331583324160.0, 406867956203520.0, 114951337279488.0, 234597201739776.0, 372619471749120.0, 417462856187904.0, 47618053373952.0, -185672631582720.0, 392255986728960.0, -136990889607168.0, 385800839626752.0, 411010804482048.0, 151194578190336.0, 168141344735232.0, 213214581227520.0, 308390658048000.0, 79505679974400.0, 9074951258112.0, 442495137742848.0, 39422380474368.0, 461230816886784.0, 421306092748800.0, 124658830540800.0, 335981265813504.0, 206772948172800.0, 308262180225024.0, 226316827754496.0, 198281332260864.0, -1206636503040.0]\n",
      "\n",
      "[27517106257920.0, 411403731075072.0, -30271270551552.0, 384331583324160.0, 406867956203520.0, 114951337279488.0, 234597201739776.0, 372619471749120.0, 417462856187904.0, 47618053373952.0, -185672631582720.0, 392255986728960.0, -136990889607168.0, 385800839626752.0, 411010804482048.0, 151194578190336.0, 168141344735232.0, 213214581227520.0, 308390658048000.0, 79505679974400.0, 9074951258112.0, 442495137742848.0, 39422380474368.0, 461230816886784.0, 421306092748800.0, 124658830540800.0, 335981265813504.0, 206772948172800.0, 308262180225024.0, 226316827754496.0, 198281332260864.0, -1206636503040.0]\n",
      "\n",
      "[27517106257920.0, 411403731075072.0, -30271270551552.0, 384331583324160.0, 406867956203520.0, 114951337279488.0, 234597201739776.0, 372619471749120.0, 417462856187904.0, 47618053373952.0, -185672631582720.0, 392255986728960.0, -136990889607168.0, 385800839626752.0, 411010804482048.0, 151194578190336.0, 168141344735232.0, 213214581227520.0, 308390658048000.0, 79505679974400.0, 9074951258112.0, 442495137742848.0, 39422380474368.0, 461230816886784.0, 421306092748800.0, 124658830540800.0, 335981265813504.0, 206772948172800.0, 308262180225024.0, 226316827754496.0, 198281332260864.0, -1206636503040.0]\n",
      "\n",
      "[27517106257920.0, 411403731075072.0, -30271270551552.0, 384331583324160.0, 406867956203520.0, 114951337279488.0, 234597201739776.0, 372619471749120.0, 417462856187904.0, 47618053373952.0, -185672631582720.0, 392255986728960.0, -136990889607168.0, 385800839626752.0, 411010804482048.0, 151194578190336.0, 168141344735232.0, 213214581227520.0, 308390658048000.0, 79505679974400.0, 9074951258112.0, 442495137742848.0, 39422380474368.0, 461230816886784.0, 421306092748800.0, 124658830540800.0, 335981265813504.0, 206772948172800.0, 308262180225024.0, 226316827754496.0, 198281332260864.0, -1206636503040.0]\n",
      "\n",
      "[522825028861952.0, 7816671129501696.0, -575154155421696.0, 7302300242542592.0, 7730491167866880.0, 2184075368464384.0, 4457346872901632.0, 7079770202308608.0, 7931794506645504.0, 904743043989504.0, -3527779920379904.0, 7452863508774912.0, -2602826962305024.0, 7330215952908288.0, 7809204966391808.0, 2872696945770496.0, 3194685510123520.0, 4051076923785216.0, 5859422622449664.0, 1510607979282432.0, 172424075149312.0, 8407407776497664.0, 749025233993728.0, 8763385839616000.0, 8004815762227200.0, 2368517840044032.0, 6383644050456576.0, 3928685975437312.0, 5856981503967232.0, 4300019687489536.0, 3767345193418752.0, -22926093713408.0]\n",
      "\n",
      "[522825028861952.0, 7816671129501696.0, -575154155421696.0, 7302300242542592.0, 7730491167866880.0, 2184075368464384.0, 4457346872901632.0, 7079770202308608.0, 7931794506645504.0, 904743043989504.0, -3527779920379904.0, 7452863508774912.0, -2602826962305024.0, 7330215952908288.0, 7809204966391808.0, 2872696945770496.0, 3194685510123520.0, 4051076923785216.0, 5859422622449664.0, 1510607979282432.0, 172424075149312.0, 8407407776497664.0, 749025233993728.0, 8763385839616000.0, 8004815762227200.0, 2368517840044032.0, 6383644050456576.0, 3928685975437312.0, 5856981503967232.0, 4300019687489536.0, 3767345193418752.0, -22926093713408.0]\n",
      "\n",
      "[522825028861952.0, 7816671129501696.0, -575154155421696.0, 7302300242542592.0, 7730491167866880.0, 2184075368464384.0, 4457346872901632.0, 7079770202308608.0, 7931794506645504.0, 904743043989504.0, -3527779920379904.0, 7452863508774912.0, -2602826962305024.0, 7330215952908288.0, 7809204966391808.0, 2872696945770496.0, 3194685510123520.0, 4051076923785216.0, 5859422622449664.0, 1510607979282432.0, 172424075149312.0, 8407407776497664.0, 749025233993728.0, 8763385839616000.0, 8004815762227200.0, 2368517840044032.0, 6383644050456576.0, 3928685975437312.0, 5856981503967232.0, 4300019687489536.0, 3767345193418752.0, -22926093713408.0]\n",
      "\n",
      "[522825028861952.0, 7816671129501696.0, -575154155421696.0, 7302300242542592.0, 7730491167866880.0, 2184075368464384.0, 4457346872901632.0, 7079770202308608.0, 7931794506645504.0, 904743043989504.0, -3527779920379904.0, 7452863508774912.0, -2602826962305024.0, 7330215952908288.0, 7809204966391808.0, 2872696945770496.0, 3194685510123520.0, 4051076923785216.0, 5859422622449664.0, 1510607979282432.0, 172424075149312.0, 8407407776497664.0, 749025233993728.0, 8763385839616000.0, 8004815762227200.0, 2368517840044032.0, 6383644050456576.0, 3928685975437312.0, 5856981503967232.0, 4300019687489536.0, 3767345193418752.0, -22926093713408.0]\n",
      "\n",
      "[1.0456500535296e+16, 1.563334272876544e+17, -1.15030834020352e+16, 1.4604600350867456e+17, 1.5460982469951488e+17, 4.36815085436928e+16, 8.914693712248832e+16, 1.41595408072704e+17, 1.5863589483053056e+17, 1.809486096367616e+16, -7.055559672987648e+16, 1.490572695044096e+17, -5.205653907832832e+16, 1.4660431704489984e+17, 1.5618410201219072e+17, 5.74539385798656e+16, 6.389371053801472e+16, 8.102154082451456e+16, 1.17188451106816e+17, 3.021215824347136e+16, 3448481586872320.0, 1.6814815217451008e+17, 1.498050501541888e+16, 1.7526771545014272e+17, 1.6009631256018944e+17, 4.737035931746304e+16, 1.2767288503566336e+17, 7.857372085092352e+16, 1.1713962806607872e+17, 8.600039576305664e+16, 7.534690118402048e+16, -458521858539520.0]\n",
      "\n",
      "[1.0456500535296e+16, 1.563334272876544e+17, -1.15030834020352e+16, 1.4604600350867456e+17, 1.5460982469951488e+17, 4.36815085436928e+16, 8.914693712248832e+16, 1.41595408072704e+17, 1.5863589483053056e+17, 1.809486096367616e+16, -7.055559672987648e+16, 1.490572695044096e+17, -5.205653907832832e+16, 1.4660431704489984e+17, 1.5618410201219072e+17, 5.74539385798656e+16, 6.389371053801472e+16, 8.102154082451456e+16, 1.17188451106816e+17, 3.021215824347136e+16, 3448481586872320.0, 1.6814815217451008e+17, 1.498050501541888e+16, 1.7526771545014272e+17, 1.6009631256018944e+17, 4.737035931746304e+16, 1.2767288503566336e+17, 7.857372085092352e+16, 1.1713962806607872e+17, 8.600039576305664e+16, 7.534690118402048e+16, -458521858539520.0]\n",
      "\n",
      "[1.0456500535296e+16, 1.563334272876544e+17, -1.15030834020352e+16, 1.4604600350867456e+17, 1.5460982469951488e+17, 4.36815085436928e+16, 8.914693712248832e+16, 1.41595408072704e+17, 1.5863589483053056e+17, 1.809486096367616e+16, -7.055559672987648e+16, 1.490572695044096e+17, -5.205653907832832e+16, 1.4660431704489984e+17, 1.5618410201219072e+17, 5.74539385798656e+16, 6.389371053801472e+16, 8.102154082451456e+16, 1.17188451106816e+17, 3.021215824347136e+16, 3448481586872320.0, 1.6814815217451008e+17, 1.498050501541888e+16, 1.7526771545014272e+17, 1.6009631256018944e+17, 4.737035931746304e+16, 1.2767288503566336e+17, 7.857372085092352e+16, 1.1713962806607872e+17, 8.600039576305664e+16, 7.534690118402048e+16, -458521858539520.0]\n",
      "\n",
      "[1.0456500535296e+16, 1.563334272876544e+17, -1.15030834020352e+16, 1.4604600350867456e+17, 1.5460982469951488e+17, 4.36815085436928e+16, 8.914693712248832e+16, 1.41595408072704e+17, 1.5863589483053056e+17, 1.809486096367616e+16, -7.055559672987648e+16, 1.490572695044096e+17, -5.205653907832832e+16, 1.4660431704489984e+17, 1.5618410201219072e+17, 5.74539385798656e+16, 6.389371053801472e+16, 8.102154082451456e+16, 1.17188451106816e+17, 3.021215824347136e+16, 3448481586872320.0, 1.6814815217451008e+17, 1.498050501541888e+16, 1.7526771545014272e+17, 1.6009631256018944e+17, 4.737035931746304e+16, 1.2767288503566336e+17, 7.857372085092352e+16, 1.1713962806607872e+17, 8.600039576305664e+16, 7.534690118402048e+16, -458521858539520.0]\n",
      "\n",
      "[2.19586511241216e+17, 3.283001927943586e+18, -2.4156474580559462e+17, 3.0669659834878525e+18, 3.2468062284954993e+18, 9.173117019661271e+17, 1.8720856119265198e+18, 2.973503569526784e+18, 3.331353656149672e+18, 3.799920689629102e+17, -1.481667531327406e+18, 3.1302026595926016e+18, -1.0931873657420513e+18, 3.078690522651427e+18, 3.279866052061692e+18, 1.2065327552743342e+18, 1.3417679438468874e+18, 1.7014524024119624e+18, 2.4609574281459794e+18, 6.344553005643203e+17, 7.241811332431872e+16, 3.5311113309561815e+18, 3.145905940495073e+17, 3.6806221146473103e+18, 3.362022608861135e+18, 9.947775231181455e+17, 2.6811305857489306e+18, 1.650048137869394e+18, 2.4599322795819663e+18, 1.806008356121346e+18, 1.5822849699615867e+18, -9628958853169152.0]\n",
      "\n",
      "[2.19586511241216e+17, 3.283001927943586e+18, -2.4156474580559462e+17, 3.0669659834878525e+18, 3.2468062284954993e+18, 9.173117019661271e+17, 1.8720856119265198e+18, 2.973503569526784e+18, 3.331353656149672e+18, 3.799920689629102e+17, -1.481667531327406e+18, 3.1302026595926016e+18, -1.0931873657420513e+18, 3.078690522651427e+18, 3.279866052061692e+18, 1.2065327552743342e+18, 1.3417679438468874e+18, 1.7014524024119624e+18, 2.4609574281459794e+18, 6.344553005643203e+17, 7.241811332431872e+16, 3.5311113309561815e+18, 3.145905940495073e+17, 3.6806221146473103e+18, 3.362022608861135e+18, 9.947775231181455e+17, 2.6811305857489306e+18, 1.650048137869394e+18, 2.4599322795819663e+18, 1.806008356121346e+18, 1.5822849699615867e+18, -9628958853169152.0]\n",
      "\n",
      "[2.19586511241216e+17, 3.283001927943586e+18, -2.4156474580559462e+17, 3.0669659834878525e+18, 3.2468062284954993e+18, 9.173117019661271e+17, 1.8720856119265198e+18, 2.973503569526784e+18, 3.331353656149672e+18, 3.799920689629102e+17, -1.481667531327406e+18, 3.1302026595926016e+18, -1.0931873657420513e+18, 3.078690522651427e+18, 3.279866052061692e+18, 1.2065327552743342e+18, 1.3417679438468874e+18, 1.7014524024119624e+18, 2.4609574281459794e+18, 6.344553005643203e+17, 7.241811332431872e+16, 3.5311113309561815e+18, 3.145905940495073e+17, 3.6806221146473103e+18, 3.362022608861135e+18, 9.947775231181455e+17, 2.6811305857489306e+18, 1.650048137869394e+18, 2.4599322795819663e+18, 1.806008356121346e+18, 1.5822849699615867e+18, -9628958853169152.0]\n",
      "\n",
      "[2.19586511241216e+17, 3.283001927943586e+18, -2.4156474580559462e+17, 3.0669659834878525e+18, 3.2468062284954993e+18, 9.173117019661271e+17, 1.8720856119265198e+18, 2.973503569526784e+18, 3.331353656149672e+18, 3.799920689629102e+17, -1.481667531327406e+18, 3.1302026595926016e+18, -1.0931873657420513e+18, 3.078690522651427e+18, 3.279866052061692e+18, 1.2065327552743342e+18, 1.3417679438468874e+18, 1.7014524024119624e+18, 2.4609574281459794e+18, 6.344553005643203e+17, 7.241811332431872e+16, 3.5311113309561815e+18, 3.145905940495073e+17, 3.6806221146473103e+18, 3.362022608861135e+18, 9.947775231181455e+17, 2.6811305857489306e+18, 1.650048137869394e+18, 2.4599322795819663e+18, 1.806008356121346e+18, 1.5822849699615867e+18, -9628958853169152.0]\n",
      "\n",
      "[4.830903176439792e+18, 7.222603976905903e+19, -5.314424478590042e+18, 6.747325012490427e+19, 7.1429735515072496e+19, 2.0180857254276235e+19, 4.118588478523336e+19, 6.541707871856781e+19, 7.328978043529278e+19, 8.359825706162586e+18, -3.259668521675653e+19, 6.886445888899436e+19, -2.405012223530369e+19, 6.773119225424563e+19, 7.2157052011485856e+19, 2.654372004909967e+19, 2.951889570952433e+19, 3.74319541759131e+19, 5.414106360819011e+19, 1.3958016990372168e+19, 1.593198499040592e+18, 7.768444814716463e+19, 6.92099283286596e+18, 8.097368501041234e+19, 7.396449739494497e+19, 2.188510522513136e+19, 5.8984871374647984e+19, 3.630105808823386e+19, 5.4118513174460236e+19, 3.973218307875537e+19, 3.481026820528354e+19, -2.1183710067530138e+17]\n",
      "\n",
      "[4.830903176439792e+18, 7.222603976905903e+19, -5.314424478590042e+18, 6.747325012490427e+19, 7.1429735515072496e+19, 2.0180857254276235e+19, 4.118588478523336e+19, 6.541707871856781e+19, 7.328978043529278e+19, 8.359825706162586e+18, -3.259668521675653e+19, 6.886445888899436e+19, -2.405012223530369e+19, 6.773119225424563e+19, 7.2157052011485856e+19, 2.654372004909967e+19, 2.951889570952433e+19, 3.74319541759131e+19, 5.414106360819011e+19, 1.3958016990372168e+19, 1.593198499040592e+18, 7.768444814716463e+19, 6.92099283286596e+18, 8.097368501041234e+19, 7.396449739494497e+19, 2.188510522513136e+19, 5.8984871374647984e+19, 3.630105808823386e+19, 5.4118513174460236e+19, 3.973218307875537e+19, 3.481026820528354e+19, -2.1183710067530138e+17]\n",
      "\n",
      "[4.830903176439792e+18, 7.222603976905903e+19, -5.314424478590042e+18, 6.747325012490427e+19, 7.1429735515072496e+19, 2.0180857254276235e+19, 4.118588478523336e+19, 6.541707871856781e+19, 7.328978043529278e+19, 8.359825706162586e+18, -3.259668521675653e+19, 6.886445888899436e+19, -2.405012223530369e+19, 6.773119225424563e+19, 7.2157052011485856e+19, 2.654372004909967e+19, 2.951889570952433e+19, 3.74319541759131e+19, 5.414106360819011e+19, 1.3958016990372168e+19, 1.593198499040592e+18, 7.768444814716463e+19, 6.92099283286596e+18, 8.097368501041234e+19, 7.396449739494497e+19, 2.188510522513136e+19, 5.8984871374647984e+19, 3.630105808823386e+19, 5.4118513174460236e+19, 3.973218307875537e+19, 3.481026820528354e+19, -2.1183710067530138e+17]\n",
      "\n",
      "[4.830903176439792e+18, 7.222603976905903e+19, -5.314424478590042e+18, 6.747325012490427e+19, 7.1429735515072496e+19, 2.0180857254276235e+19, 4.118588478523336e+19, 6.541707871856781e+19, 7.328978043529278e+19, 8.359825706162586e+18, -3.259668521675653e+19, 6.886445888899436e+19, -2.405012223530369e+19, 6.773119225424563e+19, 7.2157052011485856e+19, 2.654372004909967e+19, 2.951889570952433e+19, 3.74319541759131e+19, 5.414106360819011e+19, 1.3958016990372168e+19, 1.593198499040592e+18, 7.768444814716463e+19, 6.92099283286596e+18, 8.097368501041234e+19, 7.396449739494497e+19, 2.188510522513136e+19, 5.8984871374647984e+19, 3.630105808823386e+19, 5.4118513174460236e+19, 3.973218307875537e+19, 3.481026820528354e+19, -2.1183710067530138e+17]\n",
      "\n",
      "[1.1111077700948512e+20, 1.661198902043974e+21, -1.2223176537839292e+20, 1.551884765517182e+21, 1.6428839674242023e+21, 4.641596978817778e+20, 9.472753500603673e+20, 1.5045928484602108e+21, 1.6856649753005014e+21, 1.9227598650009557e+20, -7.497237473410165e+20, 1.5838825418024865e+21, -5.531527924454093e+20, 1.5578174092032659e+21, 1.659612183619791e+21, 6.105055421627168e+20, 6.789346202856351e+20, 8.609349460460013e+20, 1.2452445009215236e+21, 3.2103437813417614e+20, 3.6643566268207596e+19, 1.7867422568072515e+21, 1.5918283989756097e+20, 1.8623947173063326e+21, 1.7011834780168854e+21, 5.0335743914459687e+20, 1.3566520416169036e+21, 8.349243360293788e+20, 1.244725777723818e+21, 9.138401602338386e+20, 8.006361560771377e+20, -4.872253266139808e+18]\n",
      "\n",
      "[1.1111077700948512e+20, 1.661198902043974e+21, -1.2223176537839292e+20, 1.551884765517182e+21, 1.6428839674242023e+21, 4.641596978817778e+20, 9.472753500603673e+20, 1.5045928484602108e+21, 1.6856649753005014e+21, 1.9227598650009557e+20, -7.497237473410165e+20, 1.5838825418024865e+21, -5.531527924454093e+20, 1.5578174092032659e+21, 1.659612183619791e+21, 6.105055421627168e+20, 6.789346202856351e+20, 8.609349460460013e+20, 1.2452445009215236e+21, 3.2103437813417614e+20, 3.6643566268207596e+19, 1.7867422568072515e+21, 1.5918283989756097e+20, 1.8623947173063326e+21, 1.7011834780168854e+21, 5.0335743914459687e+20, 1.3566520416169036e+21, 8.349243360293788e+20, 1.244725777723818e+21, 9.138401602338386e+20, 8.006361560771377e+20, -4.872253266139808e+18]\n",
      "\n",
      "[1.1111077700948512e+20, 1.661198902043974e+21, -1.2223176537839292e+20, 1.551884765517182e+21, 1.6428839674242023e+21, 4.641596978817778e+20, 9.472753500603673e+20, 1.5045928484602108e+21, 1.6856649753005014e+21, 1.9227598650009557e+20, -7.497237473410165e+20, 1.5838825418024865e+21, -5.531527924454093e+20, 1.5578174092032659e+21, 1.659612183619791e+21, 6.105055421627168e+20, 6.789346202856351e+20, 8.609349460460013e+20, 1.2452445009215236e+21, 3.2103437813417614e+20, 3.6643566268207596e+19, 1.7867422568072515e+21, 1.5918283989756097e+20, 1.8623947173063326e+21, 1.7011834780168854e+21, 5.0335743914459687e+20, 1.3566520416169036e+21, 8.349243360293788e+20, 1.244725777723818e+21, 9.138401602338386e+20, 8.006361560771377e+20, -4.872253266139808e+18]\n",
      "\n",
      "[1.1111077700948512e+20, 1.661198902043974e+21, -1.2223176537839292e+20, 1.551884765517182e+21, 1.6428839674242023e+21, 4.641596978817778e+20, 9.472753500603673e+20, 1.5045928484602108e+21, 1.6856649753005014e+21, 1.9227598650009557e+20, -7.497237473410165e+20, 1.5838825418024865e+21, -5.531527924454093e+20, 1.5578174092032659e+21, 1.659612183619791e+21, 6.105055421627168e+20, 6.789346202856351e+20, 8.609349460460013e+20, 1.2452445009215236e+21, 3.2103437813417614e+20, 3.6643566268207596e+19, 1.7867422568072515e+21, 1.5918283989756097e+20, 1.8623947173063326e+21, 1.7011834780168854e+21, 5.0335743914459687e+20, 1.3566520416169036e+21, 8.349243360293788e+20, 1.244725777723818e+21, 9.138401602338386e+20, 8.006361560771377e+20, -4.872253266139808e+18]\n",
      "\n",
      "[2.666658674615922e+21, 3.986877322684291e+22, -2.933562395469709e+21, 3.724523278911562e+22, 3.942921627371202e+22, 1.113983269638611e+22, 2.273460776813012e+22, 3.611022772972636e+22, 4.045595930165892e+22, 4.6146234912843403e+21, -1.799336951397193e+22, 3.80131798421754e+22, -1.3275667071466381e+22, 3.7387616343134753e+22, 3.983069304019368e+22, 1.4652133750777018e+22, 1.6294430464642778e+22, 2.0662437966232217e+22, 2.988586686103229e+22, 7.704825233549902e+21, 8.794456069296567e+20, 4.2881813107842874e+22, 3.820388223512161e+21, 4.469747194871459e+22, 4.0828404739042645e+22, 1.208057864502344e+22, 3.255965058210243e+22, 2.0038183325833277e+22, 2.9873420037562143e+22, 2.193216426782459e+22, 1.921526758752163e+22, -1.1693407756272167e+20]\n",
      "\n",
      "[2.666658674615922e+21, 3.986877322684291e+22, -2.933562395469709e+21, 3.724523278911562e+22, 3.942921627371202e+22, 1.113983269638611e+22, 2.273460776813012e+22, 3.611022772972636e+22, 4.045595930165892e+22, 4.6146234912843403e+21, -1.799336951397193e+22, 3.80131798421754e+22, -1.3275667071466381e+22, 3.7387616343134753e+22, 3.983069304019368e+22, 1.4652133750777018e+22, 1.6294430464642778e+22, 2.0662437966232217e+22, 2.988586686103229e+22, 7.704825233549902e+21, 8.794456069296567e+20, 4.2881813107842874e+22, 3.820388223512161e+21, 4.469747194871459e+22, 4.0828404739042645e+22, 1.208057864502344e+22, 3.255965058210243e+22, 2.0038183325833277e+22, 2.9873420037562143e+22, 2.193216426782459e+22, 1.921526758752163e+22, -1.1693407756272167e+20]\n",
      "\n",
      "[2.666658674615922e+21, 3.986877322684291e+22, -2.933562395469709e+21, 3.724523278911562e+22, 3.942921627371202e+22, 1.113983269638611e+22, 2.273460776813012e+22, 3.611022772972636e+22, 4.045595930165892e+22, 4.6146234912843403e+21, -1.799336951397193e+22, 3.80131798421754e+22, -1.3275667071466381e+22, 3.7387616343134753e+22, 3.983069304019368e+22, 1.4652133750777018e+22, 1.6294430464642778e+22, 2.0662437966232217e+22, 2.988586686103229e+22, 7.704825233549902e+21, 8.794456069296567e+20, 4.2881813107842874e+22, 3.820388223512161e+21, 4.469747194871459e+22, 4.0828404739042645e+22, 1.208057864502344e+22, 3.255965058210243e+22, 2.0038183325833277e+22, 2.9873420037562143e+22, 2.193216426782459e+22, 1.921526758752163e+22, -1.1693407756272167e+20]\n",
      "\n",
      "[2.666658674615922e+21, 3.986877322684291e+22, -2.933562395469709e+21, 3.724523278911562e+22, 3.942921627371202e+22, 1.113983269638611e+22, 2.273460776813012e+22, 3.611022772972636e+22, 4.045595930165892e+22, 4.6146234912843403e+21, -1.799336951397193e+22, 3.80131798421754e+22, -1.3275667071466381e+22, 3.7387616343134753e+22, 3.983069304019368e+22, 1.4652133750777018e+22, 1.6294430464642778e+22, 2.0662437966232217e+22, 2.988586686103229e+22, 7.704825233549902e+21, 8.794456069296567e+20, 4.2881813107842874e+22, 3.820388223512161e+21, 4.469747194871459e+22, 4.0828404739042645e+22, 1.208057864502344e+22, 3.255965058210243e+22, 2.0038183325833277e+22, 2.9873420037562143e+22, 2.193216426782459e+22, 1.921526758752163e+22, -1.1693407756272167e+20]\n",
      "\n",
      "[6.666646862461665e+22, 9.967193306710728e+23, -7.333905812752412e+22, 9.311308197278905e+23, 9.857304349902981e+23, 2.7849581740965275e+23, 5.68365194203253e+23, 9.027556650956613e+23, 1.0113990388364683e+24, 1.153655872821085e+23, -4.4983422377554944e+23, 9.503295523493803e+23, -3.318916767866595e+23, 9.346904085783688e+23, 9.957672697098467e+23, 3.6630334376942544e+23, 4.073607756898183e+23, 5.1656096322955426e+23, 7.471466715258072e+23, 1.9262063083874754e+23, 2.198614061304607e+22, 1.0720452995485742e+24, 9.550970910624123e+22, 1.1174367424228694e+24, 1.0207101184760661e+24, 3.020144590887116e+23, 8.139912927000585e+23, 5.0095458314583194e+23, 7.468355290865512e+23, 5.4830413484311246e+23, 4.803816896880408e+23, -2.9233520490192044e+21]\n",
      "\n",
      "[6.666646862461665e+22, 9.967193306710728e+23, -7.333905812752412e+22, 9.311308197278905e+23, 9.857304349902981e+23, 2.7849581740965275e+23, 5.68365194203253e+23, 9.027556650956613e+23, 1.0113990388364683e+24, 1.153655872821085e+23, -4.4983422377554944e+23, 9.503295523493803e+23, -3.318916767866595e+23, 9.346904085783688e+23, 9.957672697098467e+23, 3.6630334376942544e+23, 4.073607756898183e+23, 5.1656096322955426e+23, 7.471466715258072e+23, 1.9262063083874754e+23, 2.198614061304607e+22, 1.0720452995485742e+24, 9.550970910624123e+22, 1.1174367424228694e+24, 1.0207101184760661e+24, 3.020144590887116e+23, 8.139912927000585e+23, 5.0095458314583194e+23, 7.468355290865512e+23, 5.4830413484311246e+23, 4.803816896880408e+23, -2.9233520490192044e+21]\n",
      "\n",
      "[6.666646862461665e+22, 9.967193306710728e+23, -7.333905812752412e+22, 9.311308197278905e+23, 9.857304349902981e+23, 2.7849581740965275e+23, 5.68365194203253e+23, 9.027556650956613e+23, 1.0113990388364683e+24, 1.153655872821085e+23, -4.4983422377554944e+23, 9.503295523493803e+23, -3.318916767866595e+23, 9.346904085783688e+23, 9.957672697098467e+23, 3.6630334376942544e+23, 4.073607756898183e+23, 5.1656096322955426e+23, 7.471466715258072e+23, 1.9262063083874754e+23, 2.198614061304607e+22, 1.0720452995485742e+24, 9.550970910624123e+22, 1.1174367424228694e+24, 1.0207101184760661e+24, 3.020144590887116e+23, 8.139912927000585e+23, 5.0095458314583194e+23, 7.468355290865512e+23, 5.4830413484311246e+23, 4.803816896880408e+23, -2.9233520490192044e+21]\n",
      "\n",
      "[6.666646862461665e+22, 9.967193306710728e+23, -7.333905812752412e+22, 9.311308197278905e+23, 9.857304349902981e+23, 2.7849581740965275e+23, 5.68365194203253e+23, 9.027556650956613e+23, 1.0113990388364683e+24, 1.153655872821085e+23, -4.4983422377554944e+23, 9.503295523493803e+23, -3.318916767866595e+23, 9.346904085783688e+23, 9.957672697098467e+23, 3.6630334376942544e+23, 4.073607756898183e+23, 5.1656096322955426e+23, 7.471466715258072e+23, 1.9262063083874754e+23, 2.198614061304607e+22, 1.0720452995485742e+24, 9.550970910624123e+22, 1.1174367424228694e+24, 1.0207101184760661e+24, 3.020144590887116e+23, 8.139912927000585e+23, 5.0095458314583194e+23, 7.468355290865512e+23, 5.4830413484311246e+23, 4.803816896880408e+23, -2.9233520490192044e+21]\n",
      "\n",
      "[1.73332822083178e+24, 2.591470189488635e+25, -1.906815489360579e+24, 2.4209401430018744e+25, 2.562899166102852e+25, 7.240891047737188e+24, 1.4777494932190987e+25, 2.3471648112142327e+25, 2.6296374541373815e+25, 2.9995052400614236e+24, -1.169568999380467e+25, 2.4708568595271068e+25, -8.629184035554111e+24, 2.4301950330303614e+25, 2.5889949246643194e+25, 9.523886791638074e+24, 1.059138034357566e+25, 1.3430585161062e+25, 1.9425813518217783e+25, 5.008136416444135e+24, 5.716396669167219e+23, 2.787317743698216e+25, 2.4832524806723685e+24, 2.9053355302994603e+25, 2.6538462260722587e+25, 7.852375789939514e+24, 2.1163772790546388e+25, 1.3024819337432016e+25, 1.9417723756250332e+25, 1.4255907623014514e+25, 1.2489923639155084e+25, -7.600715464668983e+22]\n",
      "\n",
      "[1.73332822083178e+24, 2.591470189488635e+25, -1.906815489360579e+24, 2.4209401430018744e+25, 2.562899166102852e+25, 7.240891047737188e+24, 1.4777494932190987e+25, 2.3471648112142327e+25, 2.6296374541373815e+25, 2.9995052400614236e+24, -1.169568999380467e+25, 2.4708568595271068e+25, -8.629184035554111e+24, 2.4301950330303614e+25, 2.5889949246643194e+25, 9.523886791638074e+24, 1.059138034357566e+25, 1.3430585161062e+25, 1.9425813518217783e+25, 5.008136416444135e+24, 5.716396669167219e+23, 2.787317743698216e+25, 2.4832524806723685e+24, 2.9053355302994603e+25, 2.6538462260722587e+25, 7.852375789939514e+24, 2.1163772790546388e+25, 1.3024819337432016e+25, 1.9417723756250332e+25, 1.4255907623014514e+25, 1.2489923639155084e+25, -7.600715464668983e+22]\n",
      "\n",
      "[1.73332822083178e+24, 2.591470189488635e+25, -1.906815489360579e+24, 2.4209401430018744e+25, 2.562899166102852e+25, 7.240891047737188e+24, 1.4777494932190987e+25, 2.3471648112142327e+25, 2.6296374541373815e+25, 2.9995052400614236e+24, -1.169568999380467e+25, 2.4708568595271068e+25, -8.629184035554111e+24, 2.4301950330303614e+25, 2.5889949246643194e+25, 9.523886791638074e+24, 1.059138034357566e+25, 1.3430585161062e+25, 1.9425813518217783e+25, 5.008136416444135e+24, 5.716396669167219e+23, 2.787317743698216e+25, 2.4832524806723685e+24, 2.9053355302994603e+25, 2.6538462260722587e+25, 7.852375789939514e+24, 2.1163772790546388e+25, 1.3024819337432016e+25, 1.9417723756250332e+25, 1.4255907623014514e+25, 1.2489923639155084e+25, -7.600715464668983e+22]\n",
      "\n",
      "[1.73332822083178e+24, 2.591470189488635e+25, -1.906815489360579e+24, 2.4209401430018744e+25, 2.562899166102852e+25, 7.240891047737188e+24, 1.4777494932190987e+25, 2.3471648112142327e+25, 2.6296374541373815e+25, 2.9995052400614236e+24, -1.169568999380467e+25, 2.4708568595271068e+25, -8.629184035554111e+24, 2.4301950330303614e+25, 2.5889949246643194e+25, 9.523886791638074e+24, 1.059138034357566e+25, 1.3430585161062e+25, 1.9425813518217783e+25, 5.008136416444135e+24, 5.716396669167219e+23, 2.787317743698216e+25, 2.4832524806723685e+24, 2.9053355302994603e+25, 2.6538462260722587e+25, 7.852375789939514e+24, 2.1163772790546388e+25, 1.3024819337432016e+25, 1.9417723756250332e+25, 1.4255907623014514e+25, 1.2489923639155084e+25, -7.600715464668983e+22]\n",
      "\n",
      "[4.679986342162434e+25, 6.996969239241609e+26, -5.148401675356935e+25, 6.536538230460658e+26, 6.919827515011096e+26, 1.955040631527917e+26, 3.9899237289693184e+26, 6.337345145922831e+26, 7.100021398548635e+26, 8.098663904971464e+25, -3.157836298327261e+26, 6.671313832011994e+26, -2.3298796701440597e+26, 6.561526628093076e+26, 6.990286491149166e+26, 2.57144943374228e+26, 2.859672673309878e+26, 3.626258090764492e+26, 5.244969844474305e+26, 1.352196861623242e+26, 1.543427100675149e+25, 7.525758024718485e+26, 6.704781892370899e+25, 7.844405698341938e+26, 7.165384576928494e+26, 2.12014152165032e+26, 5.71421841998092e+26, 3.516701240562195e+26, 5.242785219632086e+26, 3.84909511658057e+26, 3.3722794214829736e+26, -2.0521930994623816e+24]\n",
      "\n",
      "[4.679986342162434e+25, 6.996969239241609e+26, -5.148401675356935e+25, 6.536538230460658e+26, 6.919827515011096e+26, 1.955040631527917e+26, 3.9899237289693184e+26, 6.337345145922831e+26, 7.100021398548635e+26, 8.098663904971464e+25, -3.157836298327261e+26, 6.671313832011994e+26, -2.3298796701440597e+26, 6.561526628093076e+26, 6.990286491149166e+26, 2.57144943374228e+26, 2.859672673309878e+26, 3.626258090764492e+26, 5.244969844474305e+26, 1.352196861623242e+26, 1.543427100675149e+25, 7.525758024718485e+26, 6.704781892370899e+25, 7.844405698341938e+26, 7.165384576928494e+26, 2.12014152165032e+26, 5.71421841998092e+26, 3.516701240562195e+26, 5.242785219632086e+26, 3.84909511658057e+26, 3.3722794214829736e+26, -2.0521930994623816e+24]\n",
      "\n",
      "[4.679986342162434e+25, 6.996969239241609e+26, -5.148401675356935e+25, 6.536538230460658e+26, 6.919827515011096e+26, 1.955040631527917e+26, 3.9899237289693184e+26, 6.337345145922831e+26, 7.100021398548635e+26, 8.098663904971464e+25, -3.157836298327261e+26, 6.671313832011994e+26, -2.3298796701440597e+26, 6.561526628093076e+26, 6.990286491149166e+26, 2.57144943374228e+26, 2.859672673309878e+26, 3.626258090764492e+26, 5.244969844474305e+26, 1.352196861623242e+26, 1.543427100675149e+25, 7.525758024718485e+26, 6.704781892370899e+25, 7.844405698341938e+26, 7.165384576928494e+26, 2.12014152165032e+26, 5.71421841998092e+26, 3.516701240562195e+26, 5.242785219632086e+26, 3.84909511658057e+26, 3.3722794214829736e+26, -2.0521930994623816e+24]\n",
      "\n",
      "[4.679986342162434e+25, 6.996969239241609e+26, -5.148401675356935e+25, 6.536538230460658e+26, 6.919827515011096e+26, 1.955040631527917e+26, 3.9899237289693184e+26, 6.337345145922831e+26, 7.100021398548635e+26, 8.098663904971464e+25, -3.157836298327261e+26, 6.671313832011994e+26, -2.3298796701440597e+26, 6.561526628093076e+26, 6.990286491149166e+26, 2.57144943374228e+26, 2.859672673309878e+26, 3.626258090764492e+26, 5.244969844474305e+26, 1.352196861623242e+26, 1.543427100675149e+25, 7.525758024718485e+26, 6.704781892370899e+25, 7.844405698341938e+26, 7.165384576928494e+26, 2.12014152165032e+26, 5.71421841998092e+26, 3.516701240562195e+26, 5.242785219632086e+26, 3.84909511658057e+26, 3.3722794214829736e+26, -2.0521930994623816e+24]\n",
      "\n",
      "[1.3103962121225089e+27, 1.9591514773766966e+28, -1.4415525255930956e+27, 1.8302306657908216e+28, 1.9375516977467465e+28, 5.47411351002375e+27, 1.1171786505677696e+28, 1.7744565956638698e+28, 1.988005933486374e+28, 2.26762589339201e+27, -8.841941183371101e+27, 1.867967834225196e+28, -6.523663076403367e+27, 1.8372275010605844e+28, 1.95728026917265e+28, 7.200058253069373e+27, 8.007083678958471e+27, 1.0153522395886161e+28, 1.4685915306273637e+28, 3.786151277108682e+27, 4.321595841538165e+26, 2.107212246921176e+28, 1.8773389056525e+27, 2.196433569710301e+28, 2.0063077009090595e+28, 5.936396147634588e+27, 1.5999811511382972e+28, 9.846763667264958e+27, 1.4679798808660653e+28, 1.0777466100452981e+28, 9.442382702970347e+27, -5.746140602834195e+25]\n",
      "\n",
      "[1.3103962121225089e+27, 1.9591514773766966e+28, -1.4415525255930956e+27, 1.8302306657908216e+28, 1.9375516977467465e+28, 5.47411351002375e+27, 1.1171786505677696e+28, 1.7744565956638698e+28, 1.988005933486374e+28, 2.26762589339201e+27, -8.841941183371101e+27, 1.867967834225196e+28, -6.523663076403367e+27, 1.8372275010605844e+28, 1.95728026917265e+28, 7.200058253069373e+27, 8.007083678958471e+27, 1.0153522395886161e+28, 1.4685915306273637e+28, 3.786151277108682e+27, 4.321595841538165e+26, 2.107212246921176e+28, 1.8773389056525e+27, 2.196433569710301e+28, 2.0063077009090595e+28, 5.936396147634588e+27, 1.5999811511382972e+28, 9.846763667264958e+27, 1.4679798808660653e+28, 1.0777466100452981e+28, 9.442382702970347e+27, -5.746140602834195e+25]\n",
      "\n",
      "[1.3103962121225089e+27, 1.9591514773766966e+28, -1.4415525255930956e+27, 1.8302306657908216e+28, 1.9375516977467465e+28, 5.47411351002375e+27, 1.1171786505677696e+28, 1.7744565956638698e+28, 1.988005933486374e+28, 2.26762589339201e+27, -8.841941183371101e+27, 1.867967834225196e+28, -6.523663076403367e+27, 1.8372275010605844e+28, 1.95728026917265e+28, 7.200058253069373e+27, 8.007083678958471e+27, 1.0153522395886161e+28, 1.4685915306273637e+28, 3.786151277108682e+27, 4.321595841538165e+26, 2.107212246921176e+28, 1.8773389056525e+27, 2.196433569710301e+28, 2.0063077009090595e+28, 5.936396147634588e+27, 1.5999811511382972e+28, 9.846763667264958e+27, 1.4679798808660653e+28, 1.0777466100452981e+28, 9.442382702970347e+27, -5.746140602834195e+25]\n",
      "\n",
      "[1.3103962121225089e+27, 1.9591514773766966e+28, -1.4415525255930956e+27, 1.8302306657908216e+28, 1.9375516977467465e+28, 5.47411351002375e+27, 1.1171786505677696e+28, 1.7744565956638698e+28, 1.988005933486374e+28, 2.26762589339201e+27, -8.841941183371101e+27, 1.867967834225196e+28, -6.523663076403367e+27, 1.8372275010605844e+28, 1.95728026917265e+28, 7.200058253069373e+27, 8.007083678958471e+27, 1.0153522395886161e+28, 1.4685915306273637e+28, 3.786151277108682e+27, 4.321595841538165e+26, 2.107212246921176e+28, 1.8773389056525e+27, 2.196433569710301e+28, 2.0063077009090595e+28, 5.936396147634588e+27, 1.5999811511382972e+28, 9.846763667264958e+27, 1.4679798808660653e+28, 1.0777466100452981e+28, 9.442382702970347e+27, -5.746140602834195e+25]\n",
      "\n",
      "[3.800148961659718e+28, 5.681539113206635e+29, -4.180502377715535e+28, 5.307669016386275e+29, 5.618899837872672e+29, 1.5874929179068875e+29, 3.239818001053639e+29, 5.1459241274252225e+29, 5.765217463889162e+29, 6.576115197827944e+28, -2.5641629431776194e+29, 5.417106719253068e+29, -1.8918622707587534e+29, 5.327959667482802e+29, 5.6761128661935774e+29, 2.088016871991895e+29, 2.3220542027032873e+29, 2.9445214948069868e+29, 4.2589153960229086e+29, 1.097983913157964e+29, 1.2532627940460678e+28, 6.11091551607141e+29, 5.4442827194011345e+28, 6.369657352159873e+29, 5.81829258941495e+29, 1.7215548400175844e+29, 4.639945509486847e+29, 2.8555613779139453e+29, 4.257141568918697e+29, 3.1254652119278108e+29, 2.7382908982685082e+29, -1.6663807413871928e+27]\n",
      "\n",
      "[3.800148961659718e+28, 5.681539113206635e+29, -4.180502377715535e+28, 5.307669016386275e+29, 5.618899837872672e+29, 1.5874929179068875e+29, 3.239818001053639e+29, 5.1459241274252225e+29, 5.765217463889162e+29, 6.576115197827944e+28, -2.5641629431776194e+29, 5.417106719253068e+29, -1.8918622707587534e+29, 5.327959667482802e+29, 5.6761128661935774e+29, 2.088016871991895e+29, 2.3220542027032873e+29, 2.9445214948069868e+29, 4.2589153960229086e+29, 1.097983913157964e+29, 1.2532627940460678e+28, 6.11091551607141e+29, 5.4442827194011345e+28, 6.369657352159873e+29, 5.81829258941495e+29, 1.7215548400175844e+29, 4.639945509486847e+29, 2.8555613779139453e+29, 4.257141568918697e+29, 3.1254652119278108e+29, 2.7382908982685082e+29, -1.6663807413871928e+27]\n",
      "\n",
      "[3.800148961659718e+28, 5.681539113206635e+29, -4.180502377715535e+28, 5.307669016386275e+29, 5.618899837872672e+29, 1.5874929179068875e+29, 3.239818001053639e+29, 5.1459241274252225e+29, 5.765217463889162e+29, 6.576115197827944e+28, -2.5641629431776194e+29, 5.417106719253068e+29, -1.8918622707587534e+29, 5.327959667482802e+29, 5.6761128661935774e+29, 2.088016871991895e+29, 2.3220542027032873e+29, 2.9445214948069868e+29, 4.2589153960229086e+29, 1.097983913157964e+29, 1.2532627940460678e+28, 6.11091551607141e+29, 5.4442827194011345e+28, 6.369657352159873e+29, 5.81829258941495e+29, 1.7215548400175844e+29, 4.639945509486847e+29, 2.8555613779139453e+29, 4.257141568918697e+29, 3.1254652119278108e+29, 2.7382908982685082e+29, -1.6663807413871928e+27]\n",
      "\n",
      "[3.800148961659718e+28, 5.681539113206635e+29, -4.180502377715535e+28, 5.307669016386275e+29, 5.618899837872672e+29, 1.5874929179068875e+29, 3.239818001053639e+29, 5.1459241274252225e+29, 5.765217463889162e+29, 6.576115197827944e+28, -2.5641629431776194e+29, 5.417106719253068e+29, -1.8918622707587534e+29, 5.327959667482802e+29, 5.6761128661935774e+29, 2.088016871991895e+29, 2.3220542027032873e+29, 2.9445214948069868e+29, 4.2589153960229086e+29, 1.097983913157964e+29, 1.2532627940460678e+28, 6.11091551607141e+29, 5.4442827194011345e+28, 6.369657352159873e+29, 5.81829258941495e+29, 1.7215548400175844e+29, 4.639945509486847e+29, 2.8555613779139453e+29, 4.257141568918697e+29, 3.1254652119278108e+29, 2.7382908982685082e+29, -1.6663807413871928e+27]\n",
      "\n",
      "[1.1400446973523525e+30, 1.7044617552126397e+31, -1.2541506956057862e+30, 1.5923007155412071e+31, 1.6856699478200268e+31, 4.762479019353777e+30, 9.719454180249661e+30, 1.5437772665617657e+31, 1.7295652887515968e+31, 1.9728346169022248e+30, -7.692489059748224e+30, 1.6251320051505958e+31, -5.675586546643145e+30, 1.5983879214954898e+31, 1.7028338988175967e+31, 6.264050456595816e+30, 6.966162838325228e+30, 8.83356448442096e+30, 1.2776745975562234e+31, 3.2939517748916406e+30, 3.7597884596145285e+29, 1.8332746902391716e+31, 1.6332848025386846e+30, 1.9108971348124646e+31, 1.7454877484902861e+31, 5.164664272128513e+30, 1.3919837095144518e+31, 8.566684098324087e+30, 1.2771424813009337e+31, 9.376395600365684e+30, 8.214872517716781e+30, -4.999142168821346e+28]\n",
      "\n",
      "[1.1400446973523525e+30, 1.7044617552126397e+31, -1.2541506956057862e+30, 1.5923007155412071e+31, 1.6856699478200268e+31, 4.762479019353777e+30, 9.719454180249661e+30, 1.5437772665617657e+31, 1.7295652887515968e+31, 1.9728346169022248e+30, -7.692489059748224e+30, 1.6251320051505958e+31, -5.675586546643145e+30, 1.5983879214954898e+31, 1.7028338988175967e+31, 6.264050456595816e+30, 6.966162838325228e+30, 8.83356448442096e+30, 1.2776745975562234e+31, 3.2939517748916406e+30, 3.7597884596145285e+29, 1.8332746902391716e+31, 1.6332848025386846e+30, 1.9108971348124646e+31, 1.7454877484902861e+31, 5.164664272128513e+30, 1.3919837095144518e+31, 8.566684098324087e+30, 1.2771424813009337e+31, 9.376395600365684e+30, 8.214872517716781e+30, -4.999142168821346e+28]\n",
      "\n",
      "[1.1400446973523525e+30, 1.7044617552126397e+31, -1.2541506956057862e+30, 1.5923007155412071e+31, 1.6856699478200268e+31, 4.762479019353777e+30, 9.719454180249661e+30, 1.5437772665617657e+31, 1.7295652887515968e+31, 1.9728346169022248e+30, -7.692489059748224e+30, 1.6251320051505958e+31, -5.675586546643145e+30, 1.5983879214954898e+31, 1.7028338988175967e+31, 6.264050456595816e+30, 6.966162838325228e+30, 8.83356448442096e+30, 1.2776745975562234e+31, 3.2939517748916406e+30, 3.7597884596145285e+29, 1.8332746902391716e+31, 1.6332848025386846e+30, 1.9108971348124646e+31, 1.7454877484902861e+31, 5.164664272128513e+30, 1.3919837095144518e+31, 8.566684098324087e+30, 1.2771424813009337e+31, 9.376395600365684e+30, 8.214872517716781e+30, -4.999142168821346e+28]\n",
      "\n",
      "[1.1400446973523525e+30, 1.7044617552126397e+31, -1.2541506956057862e+30, 1.5923007155412071e+31, 1.6856699478200268e+31, 4.762479019353777e+30, 9.719454180249661e+30, 1.5437772665617657e+31, 1.7295652887515968e+31, 1.9728346169022248e+30, -7.692489059748224e+30, 1.6251320051505958e+31, -5.675586546643145e+30, 1.5983879214954898e+31, 1.7028338988175967e+31, 6.264050456595816e+30, 6.966162838325228e+30, 8.83356448442096e+30, 1.2776745975562234e+31, 3.2939517748916406e+30, 3.7597884596145285e+29, 1.8332746902391716e+31, 1.6332848025386846e+30, 1.9108971348124646e+31, 1.7454877484902861e+31, 5.164664272128513e+30, 1.3919837095144518e+31, 8.566684098324087e+30, 1.2771424813009337e+31, 9.376395600365684e+30, 8.214872517716781e+30, -4.999142168821346e+28]\n",
      "\n",
      "[3.534138576431629e+31, 5.28383137089037e+32, -3.887867097820593e+31, 4.9361322884465554e+32, 5.225576838242083e+32, 1.4763684725767332e+32, 3.013030772454457e+32, 4.7857094326497225e+32, 5.361652488821701e+32, 6.115787136724864e+31, -2.3846716787907628e+32, 5.0379092628127226e+32, -1.7594317709020307e+32, 4.9550025566360185e+32, 5.278785133180425e+32, 1.9418556064102964e+32, 2.159510538438165e+32, 2.73840507215078e+32, 3.960791416384857e+32, 1.0211250326492053e+32, 1.1655344005214997e+31, 5.683151610010245e+32, 5.063182800033906e+31, 5.923781258456267e+32, 5.411011926628136e+32, 1.6010458658024946e+32, 4.315149358957174e+32, 2.655672070480467e+32, 3.959141692032894e+32, 2.9066825775560176e+32, 2.5466105624724844e+32, -1.549734026586692e+30]\n",
      "\n",
      "[3.534138576431629e+31, 5.28383137089037e+32, -3.887867097820593e+31, 4.9361322884465554e+32, 5.225576838242083e+32, 1.4763684725767332e+32, 3.013030772454457e+32, 4.7857094326497225e+32, 5.361652488821701e+32, 6.115787136724864e+31, -2.3846716787907628e+32, 5.0379092628127226e+32, -1.7594317709020307e+32, 4.9550025566360185e+32, 5.278785133180425e+32, 1.9418556064102964e+32, 2.159510538438165e+32, 2.73840507215078e+32, 3.960791416384857e+32, 1.0211250326492053e+32, 1.1655344005214997e+31, 5.683151610010245e+32, 5.063182800033906e+31, 5.923781258456267e+32, 5.411011926628136e+32, 1.6010458658024946e+32, 4.315149358957174e+32, 2.655672070480467e+32, 3.959141692032894e+32, 2.9066825775560176e+32, 2.5466105624724844e+32, -1.549734026586692e+30]\n",
      "\n",
      "[3.534138576431629e+31, 5.28383137089037e+32, -3.887867097820593e+31, 4.9361322884465554e+32, 5.225576838242083e+32, 1.4763684725767332e+32, 3.013030772454457e+32, 4.7857094326497225e+32, 5.361652488821701e+32, 6.115787136724864e+31, -2.3846716787907628e+32, 5.0379092628127226e+32, -1.7594317709020307e+32, 4.9550025566360185e+32, 5.278785133180425e+32, 1.9418556064102964e+32, 2.159510538438165e+32, 2.73840507215078e+32, 3.960791416384857e+32, 1.0211250326492053e+32, 1.1655344005214997e+31, 5.683151610010245e+32, 5.063182800033906e+31, 5.923781258456267e+32, 5.411011926628136e+32, 1.6010458658024946e+32, 4.315149358957174e+32, 2.655672070480467e+32, 3.959141692032894e+32, 2.9066825775560176e+32, 2.5466105624724844e+32, -1.549734026586692e+30]\n",
      "\n",
      "[3.534138576431629e+31, 5.28383137089037e+32, -3.887867097820593e+31, 4.9361322884465554e+32, 5.225576838242083e+32, 1.4763684725767332e+32, 3.013030772454457e+32, 4.7857094326497225e+32, 5.361652488821701e+32, 6.115787136724864e+31, -2.3846716787907628e+32, 5.0379092628127226e+32, -1.7594317709020307e+32, 4.9550025566360185e+32, 5.278785133180425e+32, 1.9418556064102964e+32, 2.159510538438165e+32, 2.73840507215078e+32, 3.960791416384857e+32, 1.0211250326492053e+32, 1.1655344005214997e+31, 5.683151610010245e+32, 5.063182800033906e+31, 5.923781258456267e+32, 5.411011926628136e+32, 1.6010458658024946e+32, 4.315149358957174e+32, 2.655672070480467e+32, 3.959141692032894e+32, 2.9066825775560176e+32, 2.5466105624724844e+32, -1.549734026586692e+30]\n",
      "\n",
      "[1.1309243783080442e+33, 1.690826042553481e+34, -1.2441174374526668e+33, 1.5795623439085856e+34, 1.672184646265906e+34, 4.7243790445457003e+33, 9.641698471854263e+33, 1.5314270261850364e+34, 1.7157288157657574e+34, 1.957051825723517e+33, -7.630949604244198e+33, 1.612130937020133e+34, -5.630181628200872e+33, 1.5856007678322118e+34, 1.689211273566237e+34, 6.21393782445607e+33, 6.910433839059007e+33, 8.762895979425925e+33, 1.2674532725859673e+34, 3.267599988420578e+33, 3.7297102388291555e+32, 1.8186085654945925e+34, 1.6202185540392892e+33, 1.8956100452601943e+34, 1.7315238165210035e+34, 5.12334669319673e+33, 1.3808478374204846e+34, 8.498150741594373e+33, 1.266925291159212e+34, 9.301384422264574e+33, 8.149153780569137e+33, -4.959149111751006e+31]\n",
      "\n",
      "[1.1309243783080442e+33, 1.690826042553481e+34, -1.2441174374526668e+33, 1.5795623439085856e+34, 1.672184646265906e+34, 4.7243790445457003e+33, 9.641698471854263e+33, 1.5314270261850364e+34, 1.7157288157657574e+34, 1.957051825723517e+33, -7.630949604244198e+33, 1.612130937020133e+34, -5.630181628200872e+33, 1.5856007678322118e+34, 1.689211273566237e+34, 6.21393782445607e+33, 6.910433839059007e+33, 8.762895979425925e+33, 1.2674532725859673e+34, 3.267599988420578e+33, 3.7297102388291555e+32, 1.8186085654945925e+34, 1.6202185540392892e+33, 1.8956100452601943e+34, 1.7315238165210035e+34, 5.12334669319673e+33, 1.3808478374204846e+34, 8.498150741594373e+33, 1.266925291159212e+34, 9.301384422264574e+33, 8.149153780569137e+33, -4.959149111751006e+31]\n",
      "\n",
      "[1.1309243783080442e+33, 1.690826042553481e+34, -1.2441174374526668e+33, 1.5795623439085856e+34, 1.672184646265906e+34, 4.7243790445457003e+33, 9.641698471854263e+33, 1.5314270261850364e+34, 1.7157288157657574e+34, 1.957051825723517e+33, -7.630949604244198e+33, 1.612130937020133e+34, -5.630181628200872e+33, 1.5856007678322118e+34, 1.689211273566237e+34, 6.21393782445607e+33, 6.910433839059007e+33, 8.762895979425925e+33, 1.2674532725859673e+34, 3.267599988420578e+33, 3.7297102388291555e+32, 1.8186085654945925e+34, 1.6202185540392892e+33, 1.8956100452601943e+34, 1.7315238165210035e+34, 5.12334669319673e+33, 1.3808478374204846e+34, 8.498150741594373e+33, 1.266925291159212e+34, 9.301384422264574e+33, 8.149153780569137e+33, -4.959149111751006e+31]\n",
      "\n",
      "[1.1309243783080442e+33, 1.690826042553481e+34, -1.2441174374526668e+33, 1.5795623439085856e+34, 1.672184646265906e+34, 4.7243790445457003e+33, 9.641698471854263e+33, 1.5314270261850364e+34, 1.7157288157657574e+34, 1.957051825723517e+33, -7.630949604244198e+33, 1.612130937020133e+34, -5.630181628200872e+33, 1.5856007678322118e+34, 1.689211273566237e+34, 6.21393782445607e+33, 6.910433839059007e+33, 8.762895979425925e+33, 1.2674532725859673e+34, 3.267599988420578e+33, 3.7297102388291555e+32, 1.8186085654945925e+34, 1.6202185540392892e+33, 1.8956100452601943e+34, 1.7315238165210035e+34, 5.12334669319673e+33, 1.3808478374204846e+34, 8.498150741594373e+33, 1.266925291159212e+34, 9.301384422264574e+33, 8.149153780569137e+33, -4.959149111751006e+31]\n",
      "\n",
      "[3.732050448416546e+34, 5.579725940426487e+35, -4.1055875435938004e+34, 5.2125557348983325e+35, 5.51820933267749e+35, 1.5590450847000811e+35, 3.1817604957119067e+35, 5.05370918641062e+35, 5.6619050920269995e+35, 6.458271024887606e+34, -2.5182133694005854e+35, 5.3200320921664385e+35, -1.8579599373062878e+35, 5.232482533846299e+35, 5.5743972027685824e+35, 2.050599482070503e+35, 2.2804431668894723e+35, 2.8917556732105552e+35, 4.182595799533692e+35, 1.0783079961787908e+35, 1.2308043788136213e+34, 6.001408266132155e+35, 5.346721228329654e+34, 6.255513149358641e+35, 5.714028594519312e+35, 1.690704408754921e+35, 4.556797863487599e+35, 2.804389744726143e+35, 4.1808534608254e+35, 3.0694568593473095e+35, 2.6892207475878152e+35, -1.636519206877832e+33]\n",
      "\n",
      "[3.732050448416546e+34, 5.579725940426487e+35, -4.1055875435938004e+34, 5.2125557348983325e+35, 5.51820933267749e+35, 1.5590450847000811e+35, 3.1817604957119067e+35, 5.05370918641062e+35, 5.6619050920269995e+35, 6.458271024887606e+34, -2.5182133694005854e+35, 5.3200320921664385e+35, -1.8579599373062878e+35, 5.232482533846299e+35, 5.5743972027685824e+35, 2.050599482070503e+35, 2.2804431668894723e+35, 2.8917556732105552e+35, 4.182595799533692e+35, 1.0783079961787908e+35, 1.2308043788136213e+34, 6.001408266132155e+35, 5.346721228329654e+34, 6.255513149358641e+35, 5.714028594519312e+35, 1.690704408754921e+35, 4.556797863487599e+35, 2.804389744726143e+35, 4.1808534608254e+35, 3.0694568593473095e+35, 2.6892207475878152e+35, -1.636519206877832e+33]\n",
      "\n",
      "[3.732050448416546e+34, 5.579725940426487e+35, -4.1055875435938004e+34, 5.2125557348983325e+35, 5.51820933267749e+35, 1.5590450847000811e+35, 3.1817604957119067e+35, 5.05370918641062e+35, 5.6619050920269995e+35, 6.458271024887606e+34, -2.5182133694005854e+35, 5.3200320921664385e+35, -1.8579599373062878e+35, 5.232482533846299e+35, 5.5743972027685824e+35, 2.050599482070503e+35, 2.2804431668894723e+35, 2.8917556732105552e+35, 4.182595799533692e+35, 1.0783079961787908e+35, 1.2308043788136213e+34, 6.001408266132155e+35, 5.346721228329654e+34, 6.255513149358641e+35, 5.714028594519312e+35, 1.690704408754921e+35, 4.556797863487599e+35, 2.804389744726143e+35, 4.1808534608254e+35, 3.0694568593473095e+35, 2.6892207475878152e+35, -1.636519206877832e+33]\n",
      "\n",
      "[3.732050448416546e+34, 5.579725940426487e+35, -4.1055875435938004e+34, 5.2125557348983325e+35, 5.51820933267749e+35, 1.5590450847000811e+35, 3.1817604957119067e+35, 5.05370918641062e+35, 5.6619050920269995e+35, 6.458271024887606e+34, -2.5182133694005854e+35, 5.3200320921664385e+35, -1.8579599373062878e+35, 5.232482533846299e+35, 5.5743972027685824e+35, 2.050599482070503e+35, 2.2804431668894723e+35, 2.8917556732105552e+35, 4.182595799533692e+35, 1.0783079961787908e+35, 1.2308043788136213e+34, 6.001408266132155e+35, 5.346721228329654e+34, 6.255513149358641e+35, 5.714028594519312e+35, 1.690704408754921e+35, 4.556797863487599e+35, 2.804389744726143e+35, 4.1808534608254e+35, 3.0694568593473095e+35, 2.6892207475878152e+35, -1.636519206877832e+33]\n",
      "\n",
      "[1.2688971761372288e+36, 1.8971067524010675e+37, -1.3958997621912695e+36, 1.7722690045823828e+37, 1.8761912067823156e+37, 5.300753161710392e+36, 1.0817985432880715e+37, 1.718261186514553e+37, 1.9250477523341605e+37, 2.1958120695431086e+36, -8.5619251192423e+36, 1.8088109029185968e+37, -6.317064102516088e+36, 1.77904407413473e+37, 1.8952950657773025e+37, 6.972038449489517e+36, 7.753506935784051e+36, 9.831969162646004e+36, 1.4220825465874785e+37, 3.666247092305476e+36, 4.1847350589567804e+35, 2.0404787641859754e+37, 1.81788529655076e+36, 2.126874437109969e+37, 1.9427697137185737e+37, 5.748395052901673e+36, 1.5493112735857837e+37, 9.534925153113867e+36, 1.4214901893076244e+37, 1.0436153384915794e+37, 9.143350457618649e+36, -5.564165566446887e+34]\n",
      "\n",
      "[1.2688971761372288e+36, 1.8971067524010675e+37, -1.3958997621912695e+36, 1.7722690045823828e+37, 1.8761912067823156e+37, 5.300753161710392e+36, 1.0817985432880715e+37, 1.718261186514553e+37, 1.9250477523341605e+37, 2.1958120695431086e+36, -8.5619251192423e+36, 1.8088109029185968e+37, -6.317064102516088e+36, 1.77904407413473e+37, 1.8952950657773025e+37, 6.972038449489517e+36, 7.753506935784051e+36, 9.831969162646004e+36, 1.4220825465874785e+37, 3.666247092305476e+36, 4.1847350589567804e+35, 2.0404787641859754e+37, 1.81788529655076e+36, 2.126874437109969e+37, 1.9427697137185737e+37, 5.748395052901673e+36, 1.5493112735857837e+37, 9.534925153113867e+36, 1.4214901893076244e+37, 1.0436153384915794e+37, 9.143350457618649e+36, -5.564165566446887e+34]\n",
      "\n",
      "[1.2688971761372288e+36, 1.8971067524010675e+37, -1.3958997621912695e+36, 1.7722690045823828e+37, 1.8761912067823156e+37, 5.300753161710392e+36, 1.0817985432880715e+37, 1.718261186514553e+37, 1.9250477523341605e+37, 2.1958120695431086e+36, -8.5619251192423e+36, 1.8088109029185968e+37, -6.317064102516088e+36, 1.77904407413473e+37, 1.8952950657773025e+37, 6.972038449489517e+36, 7.753506935784051e+36, 9.831969162646004e+36, 1.4220825465874785e+37, 3.666247092305476e+36, 4.1847350589567804e+35, 2.0404787641859754e+37, 1.81788529655076e+36, 2.126874437109969e+37, 1.9427697137185737e+37, 5.748395052901673e+36, 1.5493112735857837e+37, 9.534925153113867e+36, 1.4214901893076244e+37, 1.0436153384915794e+37, 9.143350457618649e+36, -5.564165566446887e+34]\n",
      "\n",
      "[1.2688971761372288e+36, 1.8971067524010675e+37, -1.3958997621912695e+36, 1.7722690045823828e+37, 1.8761912067823156e+37, 5.300753161710392e+36, 1.0817985432880715e+37, 1.718261186514553e+37, 1.9250477523341605e+37, 2.1958120695431086e+36, -8.5619251192423e+36, 1.8088109029185968e+37, -6.317064102516088e+36, 1.77904407413473e+37, 1.8952950657773025e+37, 6.972038449489517e+36, 7.753506935784051e+36, 9.831969162646004e+36, 1.4220825465874785e+37, 3.666247092305476e+36, 4.1847350589567804e+35, 2.0404787641859754e+37, 1.81788529655076e+36, 2.126874437109969e+37, 1.9427697137185737e+37, 5.748395052901673e+36, 1.5493112735857837e+37, 9.534925153113867e+36, 1.4214901893076244e+37, 1.0436153384915794e+37, 9.143350457618649e+36, -5.564165566446887e+34]\n",
      "\n",
      "[4.441140116480301e+37, 6.639873855242591e+38, -4.885649167669443e+37, 6.202941377389055e+38, 6.566669251467961e+38, 1.855263634328494e+38, 3.786294998562749e+38, 6.013914263720363e+38, 6.737667077709848e+38, 7.685342035426954e+37, -2.996673791734805e+38, 6.330838132485232e+38, -2.2109724774754163e+38, 6.2266541762819846e+38, 6.6335328134101296e+38, 2.440213429591474e+38, 2.713727427524418e+38, 3.441189165331316e+38, 4.977288802136747e+38, 1.2831864823069165e+38, 1.4646572099758112e+37, 7.141675563731486e+38, 6.362598468603018e+37, 7.444060113937038e+38, 6.7996941089344354e+38, 2.011938213055872e+38, 5.4225894852801e+38, 3.337223720400283e+38, 4.975215496197544e+38, 3.652653726315313e+38, 3.200172563112028e+38, -1.947457969920361e+36]\n",
      "\n",
      "[4.441140116480301e+37, 6.639873855242591e+38, -4.885649167669443e+37, 6.202941377389055e+38, 6.566669251467961e+38, 1.855263634328494e+38, 3.786294998562749e+38, 6.013914263720363e+38, 6.737667077709848e+38, 7.685342035426954e+37, -2.996673791734805e+38, 6.330838132485232e+38, -2.2109724774754163e+38, 6.2266541762819846e+38, 6.6335328134101296e+38, 2.440213429591474e+38, 2.713727427524418e+38, 3.441189165331316e+38, 4.977288802136747e+38, 1.2831864823069165e+38, 1.4646572099758112e+37, 7.141675563731486e+38, 6.362598468603018e+37, 7.444060113937038e+38, 6.7996941089344354e+38, 2.011938213055872e+38, 5.4225894852801e+38, 3.337223720400283e+38, 4.975215496197544e+38, 3.652653726315313e+38, 3.200172563112028e+38, -1.947457969920361e+36]\n",
      "\n",
      "[4.441140116480301e+37, 6.639873855242591e+38, -4.885649167669443e+37, 6.202941377389055e+38, 6.566669251467961e+38, 1.855263634328494e+38, 3.786294998562749e+38, 6.013914263720363e+38, 6.737667077709848e+38, 7.685342035426954e+37, -2.996673791734805e+38, 6.330838132485232e+38, -2.2109724774754163e+38, 6.2266541762819846e+38, 6.6335328134101296e+38, 2.440213429591474e+38, 2.713727427524418e+38, 3.441189165331316e+38, 4.977288802136747e+38, 1.2831864823069165e+38, 1.4646572099758112e+37, 7.141675563731486e+38, 6.362598468603018e+37, 7.444060113937038e+38, 6.7996941089344354e+38, 2.011938213055872e+38, 5.4225894852801e+38, 3.337223720400283e+38, 4.975215496197544e+38, 3.652653726315313e+38, 3.200172563112028e+38, -1.947457969920361e+36]\n",
      "\n",
      "[4.441140116480301e+37, 6.639873855242591e+38, -4.885649167669443e+37, 6.202941377389055e+38, 6.566669251467961e+38, 1.855263634328494e+38, 3.786294998562749e+38, 6.013914263720363e+38, 6.737667077709848e+38, 7.685342035426954e+37, -2.996673791734805e+38, 6.330838132485232e+38, -2.2109724774754163e+38, 6.2266541762819846e+38, 6.6335328134101296e+38, 2.440213429591474e+38, 2.713727427524418e+38, 3.441189165331316e+38, 4.977288802136747e+38, 1.2831864823069165e+38, 1.4646572099758112e+37, 7.141675563731486e+38, 6.362598468603018e+37, 7.444060113937038e+38, 6.7996941089344354e+38, 2.011938213055872e+38, 5.4225894852801e+38, 3.337223720400283e+38, 4.975215496197544e+38, 3.652653726315313e+38, 3.200172563112028e+38, -1.947457969920361e+36]\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m losses, accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mfederated_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclients\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[84], line 36\u001b[0m, in \u001b[0;36mfederated_learning\u001b[0;34m(clients)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# perform local training for each clients then report acc and loss to server\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_hospitals):\n\u001b[0;32m---> 36\u001b[0m     \u001b[43mclients\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# report to server\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     losses[i]\u001b[38;5;241m.\u001b[39mappend(clients[i]\u001b[38;5;241m.\u001b[39mlosses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[82], line 56\u001b[0m, in \u001b[0;36mClient.local_training\u001b[0;34m(self, debug)\u001b[0m\n\u001b[1;32m     53\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#### Compute gradients ####\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m#### Update weights #### \u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:3154\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3151\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3152\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "losses, accuracies = federated_learning(clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774719fe",
   "metadata": {},
   "source": [
    "### Virtualize record of training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b594544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_federated_graphs(diagnosis_title, losses, accuracies):\n",
    "    for i in range(n_hospitals):\n",
    "        plt.plot(losses[i], label=f'Hospital {i+1}')\n",
    "    legend = plt.legend(loc='upper right', shadow=True)\n",
    "    plt.title(f\"{diagnosis_title} - Training Loss\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Training Loss\")\n",
    "    plt.show()\n",
    "    for i in range(n_hospitals):\n",
    "        plt.plot(accuracies[i], label=f'Hospital {i+1}')\n",
    "    legend = plt.legend(loc='lower right', shadow=True)\n",
    "    plt.title(f\"{diagnosis_title} - Training Accuracy\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Training Accuracy (Percent %)\")\n",
    "    plt.show()\n",
    "\n",
    "plot_federated_graphs('Breast cancer', losses, accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1407c111",
   "metadata": {},
   "source": [
    "### Model parameters after training proccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59337487",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients[0].decrypted_model_params()\n",
    "global_model = clients[0].local_model\n",
    "\n",
    "print('\\nModel parameters:')\n",
    "print('  | Weights: %s' % global_model.linear.weight) ### Virtualize record of training processlobal_model.linear.weight)\n",
    "print('  | Bias: %s' % global_model.linear.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85d5ece",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4520ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for testing model\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_test[\"diagnostic\"] = (df_test[\"diagnostic\"] == \"M\").astype(int)\n",
    "test , X_test , Y_test  = scale_dataset(df_test , False)\n",
    "\n",
    "test_acc = compute_federated_accuracy(global_model, X_test, Y_test)\n",
    "print('\\nTesting Accuracy = {}'.format(to_percent(test_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7328053",
   "metadata": {},
   "source": [
    "## Thanks for reading!\n",
    "I hope you have enjoyed the explanations of this machine learning system with federated learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2312754b",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- [1] Wibawa, F., Catak, F. O., Kuzlu, M., Sarp, S., & Cali, U. (2022, June). Homomorphic encryption and federated learning based privacy-preserving cnn training: Covid-19 detection use-case. In Proceedings of the 2022 European Interdisciplinary Cybersecurity Conference (pp. 85-90).​\n",
    "\n",
    "- [2] Al Badawi, A., Bates, J., Bergamaschi, F., Cousins, D. B., Erabelli, S., Genise, N., ... & Zucca, V. (2022, November). OpenFHE: Open-source fully homomorphic encryption library. In Proceedings of the 10th Workshop on Encrypted Computing & Applied Homomorphic Cryptography (pp. 53-63)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
